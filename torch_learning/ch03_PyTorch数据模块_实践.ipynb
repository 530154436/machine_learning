{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-12T09:00:00.481117Z",
     "start_time": "2024-12-12T09:00:00.474584Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import IterableDataset, Sampler, random_split\n",
    "import random"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1.1 Dataset\n",
    "PyTorch提供了两种数据集定义方式：映射式数据集、可迭代数据集。\n",
    "\n",
    "#### 1.1.1 映射风格数据集（Map-style datasets）\n",
    "映射式数据集是实现了 `__getitem__()` 和 `__len__()` 协议的数据集，它表示从索引（可能是非整数） 或键到数据样本的映射。\n",
    "在加载数据时，PyTorch将自动使用迭代索引(如enumerate)作为key，通过字典索引的方式获取value，本质就是将数据集定义为一个字典。"
   ],
   "id": "be347c7cef937452"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T09:39:13.779519Z",
     "start_time": "2024-12-12T09:39:13.761946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class KeyMappedDataset(Dataset):\n",
    "    def __init__(self, data: list):\n",
    "        self.data = data\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "class MySampler(Sampler):\n",
    "    def __init__(self, datasource):\n",
    "        super().__init__(datasource)\n",
    "        self.datasource = datasource\n",
    "        self.indices = list(range(len(datasource)))  # 获取数据的索引\n",
    "        random.seed(1024)\n",
    "        random.shuffle(self.indices)  # 打乱索引顺序\n",
    "    def __iter__(self):\n",
    "        # 通过打乱后的索引顺序迭代数据\n",
    "        for idx in self.indices:\n",
    "            yield idx\n",
    "    def __len__(self):\n",
    "        return len(self.datasource)\n",
    "\n",
    "\n",
    "_data = ['张三', '李四']\n",
    "_dataset = KeyMappedDataset(_data)\n",
    "for item in DataLoader(_dataset, batch_size=2, shuffle=True): # 输出 ['张三', '李四']\n",
    "    print(item)\n",
    "\n",
    "_sampler = MySampler(_data)\n",
    "for item in DataLoader(_dataset, batch_size=2, sampler=_sampler): # 输出 ['李四', '张三']\n",
    "    print(item)"
   ],
   "id": "60ce0ce0d932dd7a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['张三', '李四']\n",
      "['李四', '张三']\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 1.1.2 可迭代数据集（Iterable-style datasets）\n",
    "迭代器风格。在自定义数据集类中，实现`__iter__`和`__next__`方法，即定义为迭代器。\n",
    "在后续加载数据迭代时，pytorch将依次获取value，使用这种风格时，需要继承IterableDataset类。这种方法在数据量巨大，无法一下全部加载到内存时非常实用。"
   ],
   "id": "2d66d737977f9ab8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T12:02:10.279208Z",
     "start_time": "2024-12-12T12:01:52.994522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MyIterableDataset(IterableDataset):\n",
    "    def __init__(self, data):\n",
    "        super(MyIterableDataset).__init__()\n",
    "        self.data = data\n",
    "    def __iter__(self):\n",
    "        for i in self.data:\n",
    "            yield i\n",
    "\n",
    "_data = ['张三', '李四']\n",
    "_dataset = MyIterableDataset(_data)\n",
    "for item in DataLoader(_data, batch_size=2): # 输出 tensor([0, 1]) tensor([2, 3])\n",
    "    print(item)\n",
    "\n",
    "for item in DataLoader(MyIterableDataset(_data), batch_size=2, shuffle=True):\n",
    "    print(item)"
   ],
   "id": "ce01528250c80c5c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['张三', '李四']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "DataLoader with IterableDataset: expected unspecified shuffle option, but got shuffle=True",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[68], line 14\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m item \u001B[38;5;129;01min\u001B[39;00m DataLoader(_data, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m): \u001B[38;5;66;03m# 输出 tensor([0, 1]) tensor([2, 3])\u001B[39;00m\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;28mprint\u001B[39m(item)\n\u001B[0;32m---> 14\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m item \u001B[38;5;129;01min\u001B[39;00m \u001B[43mDataLoader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mMyIterableDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_data\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m:\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;28mprint\u001B[39m(item)\n",
      "File \u001B[0;32m/app/anaconda3/envs/deeplearning/lib/python3.10/site-packages/torch/utils/data/dataloader.py:309\u001B[0m, in \u001B[0;36mDataLoader.__init__\u001B[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001B[0m\n\u001B[1;32m    307\u001B[0m \u001B[38;5;66;03m# We cannot check `shuffle is not None` here, since previously `shuffle=False` was the default.\u001B[39;00m\n\u001B[1;32m    308\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m shuffle \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m}:\n\u001B[0;32m--> 309\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    310\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataLoader with IterableDataset: expected unspecified shuffle option, but got shuffle=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mshuffle\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    312\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sampler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    313\u001B[0m     \u001B[38;5;66;03m# See NOTE [ Custom Samplers and IterableDataset ]\u001B[39;00m\n\u001B[1;32m    314\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    315\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataLoader with IterableDataset: expected unspecified sampler option, but got sampler=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msampler\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mValueError\u001B[0m: DataLoader with IterableDataset: expected unspecified shuffle option, but got shuffle=True"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "IterableDataset 在处理大数据集时确实比 Dataset 更有优势，尤其适用于不能一次性加载到内存中的数据集。\n",
    "然而，IterableDataset 在迭代过程中并没有固定的输出顺序，默认情况下，如果没有实现自定义的打乱机制，样本顺序是按照数据流的顺序输出的。\n",
    "而且，由于 IterableDataset 并不强制要求实现 __len__() 方法（有时数据总量无法获取），因此不能通过 len() 获取数据集的总量，`不能直接使用 DataLoader 中的 shuffle=True` 来打乱数据。\n",
    "如果需要打乱数据，需要在 IterableDataset 中实现自定义的打乱机制。"
   ],
   "id": "1f9131c0fa94e6a9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1.3 Dataset创建数据集\n",
    "\n",
    "Dataset创建数据集常用的方法有：\n",
    "+ 使用 torch.utils.data.TensorDataset 根据Tensor创建数据集(numpy的array，Pandas的DataFrame需要先转换成Tensor)。\n",
    "+ 使用 torchvision.datasets.ImageFolder 根据图片目录创建图片数据集。<br>\n",
    "+ 继承 torch.utils.data.Dataset 创建自定义数据集。<br>\n",
    "\n",
    "此外，还可以通过\n",
    "+ torch.utils.data.`random_split` 将一个数据集分割成多份，常用于分割训练集，验证集和测试集。<br>\n",
    "+ 调用Dataset的加法运算符(+)将多个数据集合并成一个数据集。<br>\n",
    "\n",
    "注意：TensorDataset通过每一个 tensor 的第一个维度进行索引，因此，该类中的 tensor 第一维度必须相等。\n"
   ],
   "id": "9a5143f2ba12bc32"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "8 2\n",
      "Batch 1: x device: cuda:0, y device: cuda:0\n",
      "Batch 2: x device: cuda:0, y device: cuda:0\n"
     ]
    }
   ],
   "execution_count": 67,
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader\n",
    "\n",
    "# x, y\n",
    "_dataset = TensorDataset(torch.tensor(np.random.randint(low=1, high=10, size=(10, 5))), \n",
    "                         torch.tensor(np.random.randint(low=1, high=10, size=(10, 1))))\n",
    "\n",
    "# 查看数据集大小\n",
    "print(len(_dataset))  # 10\n",
    "\n",
    "# 划分训练集、测试集\n",
    "tra_size = int(len(_dataset) * 0.8)\n",
    "val_size = len(_dataset) - tra_size\n",
    "generator = torch.Generator().manual_seed(0)\n",
    "\n",
    "_tra_dataset, _val_dataset = random_split(_dataset, [tra_size, val_size], generator=generator)\n",
    "print(len(_tra_dataset), len(_val_dataset)) # 8 2\n",
    "\n",
    "# 按批加载\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "_tra_dataloader = DataLoader(_tra_dataset, batch_size=4, shuffle=True)\n",
    "for batch_idx, (x, y) in enumerate(_tra_dataloader):\n",
    "    data, labels = x.to(device), y.to(device)  # 将数据和标签移到 GPU\n",
    "    print(f\"Batch {batch_idx + 1}: x device: {data.device}, y device: {labels.device}\")"
   ],
   "id": "f6d1078e02b188c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b234d82a2688620d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
