{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "active-poultry",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### PyTorch安装与环境配置"
   ]
  },
  {
   "cell_type": "code",
   "id": "crucial-stupid",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-11-30T06:05:37.131826Z",
     "start_time": "2024-11-30T06:05:34.589338Z"
    }
   },
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.utils.data as Data\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HAMI-core Msg(8996:140566457985920:libvgpu.c:836)]: Initializing.....\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "extended-words",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-11-30T06:05:41.283262Z",
     "start_time": "2024-11-30T06:05:41.248914Z"
    }
   },
   "source": [
    "torch.rand(2,3)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8535, 0.4592, 0.6650],\n",
       "        [0.8011, 0.2389, 0.5624]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "400ec430a8725a8e"
  },
  {
   "cell_type": "markdown",
   "id": "developmental-chamber",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 基本数据处理与计算操作\n",
    "#### 创建Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "twelve-arctic",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 0., 0.],\n        [0., 0., 0.]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个2x3的未初始化的Tensor\n",
    "torch.empty(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pharmaceutical-stadium",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.1868, 0.0614, 0.0593],\n        [0.0238, 0.2714, 0.1254]])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个2x3的随机初始化的Tensor\n",
    "torch.rand(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "trained-brooks",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0, 0, 0],\n        [0, 0, 0]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个2x3的long型全0的Tensor\n",
    "torch.zeros(2, 3, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "direct-musical",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[5, 5, 3],\n        [2, 2, 5]])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 直接根据数据创建\n",
    "x = torch.tensor([[5,5,3], [2,2,5]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "civilian-screw",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 1., 1.],\n        [1., 1., 1.]], dtype=torch.float64)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 返回的tensor默认具有相同的torch.dtype和torch.device \n",
    "x = x.new_ones(2, 3, dtype=torch.float64)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "declared-taste",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.5292,  1.2950, -0.1726],\n        [-1.1074,  2.3685, -1.5157]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指定新的数据类型\n",
    "x = torch.randn_like(x, dtype=torch.float)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "convenient-hudson",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 3])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "durable-mumbai",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 3])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-specific",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Tensor的相关操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-handling",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### 算术操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "devoted-folder",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[0.6151, 0.3719, 0.4908],\n         [0.5415, 0.0234, 0.3080]]),\n tensor([[0.6020, 0.6316, 0.1112],\n         [0.6900, 0.0738, 0.5778]]))"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2, 3) \n",
    "y = torch.rand(2, 3)\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "affecting-resolution",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1.2170, 1.0035, 0.6021],\n        [1.2314, 0.0971, 0.8858]])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加法形式1\n",
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "loved-matthew",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1.2170, 1.0035, 0.6021],\n        [1.2314, 0.0971, 0.8858]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加法形式2\n",
    "torch.add(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "unlimited-payday",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1.2170, 1.0035, 0.6021],\n        [1.2314, 0.0971, 0.8858]])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加法形式3，inplace(原地操作)\n",
    "y.add_(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "perceived-provision",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[1.2170, 1.2314],\n         [1.0035, 0.0971],\n         [0.6021, 0.8858]]),\n tensor([[1.2170, 1.2314],\n         [1.0035, 0.0971],\n         [0.6021, 0.8858]]))"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.copy_(y), x.t_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-builder",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### 索引\n",
    "索引出来的结果与原数据`共享内存`，也即修改一个，另一个会跟着修改。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "surface-letter",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[1.2170, 1.2314],\n         [1.0035, 0.0971],\n         [0.6021, 0.8858]]),\n tensor([[1.2170, 1.0035, 0.6021],\n         [1.2314, 0.0971, 0.8858]]))"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "neither-edinburgh",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1.2170, 1.2314])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x[0, :]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "chicken-blank",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([2.2170, 2.2314])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y += 1\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "breathing-default",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([2.2170, 2.2314])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-junior",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### 切片 index_select\n",
    "沿着指定维度对输入进行切片，取index中指定的相应项(index 为一个 LongTensor)，然后返回到一个新的张量， 返回的张量与原始张量 Tensor 有相同的维度(在指定轴上)。\n",
    "\n",
    "注意： `返回的张量不与原始张量共享内存空间`。<br>\n",
    "\n",
    "参数:<br>\n",
    "input (Tensor)         – 输入张量<br>\n",
    "dim (int)              – 索引的轴<br>\n",
    "index (LongTensor)     – 包含索引下标的一维张量<br>\n",
    "out (Tensor, optional) – 目标张量<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "parallel-finland",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.4803, -0.2902,  0.2463,  0.7222],\n        [ 0.1069,  1.7948,  1.9941,  0.5329],\n        [-0.0995,  0.4231, -1.3857,  0.2847]])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dressed-cornell",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0, 2])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = torch.LongTensor([0, 2])\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "lovely-calibration",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.4803, -0.2902,  0.2463,  0.7222],\n        [-0.0995,  0.4231, -1.3857,  0.2847]])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 按行(dim=0)选取第0行、第2行\n",
    "torch.index_select(x, 0, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-groove",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### 改变形状 view/reshape\n",
    "1. `view()`<br>\n",
    "注意view()**返回的新Tensor与源Tensor虽然可能有不同的size**，但`共享data`。<br>\n",
    "即更改其中的一个，另外一个也会跟着改变。(顾名思义，view仅仅是改变了对这个张量的 观察角度，内部数据并未改变)\n",
    "2. `reshape()` 和 `clone()`<br> \n",
    "Pytorch还提供了一个 reshape() 方法可以改变形状，但是此函数并不能保证返回的是其拷贝，所以不推荐使用。<br> \n",
    "我们推荐先用 clone() 创造一个副本然后再使用view()。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "timely-burden",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[ 0.7813,  0.4718,  1.5978,  0.0179],\n         [ 1.1966,  1.2976,  1.1338, -1.3107],\n         [-0.3635, -0.8384,  0.3735,  0.1435]]),\n tensor([ 0.1069, -0.4006]))"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 4)\n",
    "y = torch.randn(2)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "elementary-stock",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 0.7813,  0.4718,  1.5978,  0.0179,  1.1966,  1.2976,  1.1338, -1.3107,\n        -0.3635, -0.8384,  0.3735,  0.1435])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一个tensor必须是连续的contiguous()才能被查看。\n",
    "# 一开始不加contiguous()，报 “view size is not compatible ... ” 错误，因为在 2.2.1 索引时修改了 x 数组的值\n",
    "y = x.contiguous().view(12)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "continent-concentrate",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.7813,  0.4718,  1.5978],\n        [ 0.0179,  1.1966,  1.2976],\n        [ 1.1338, -1.3107, -0.3635],\n        [-0.8384,  0.3735,  0.1435]])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x.contiguous().view(-1, 3) # -1所指的维度可以根据其他维度的值推出来\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "monetary-privacy",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([3, 4]), torch.Size([12]), torch.Size([4, 3]))"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size(), y.size(), z.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "improved-trace",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([ 0.7813,  0.4718,  1.5978,  0.0179,  1.1966,  1.2976,  1.1338, -1.3107,\n         -0.3635, -0.8384,  0.3735,  0.1435]),\n tensor([[-0.2187, -0.5282,  0.5978, -0.9821],\n         [ 0.1966,  0.2976,  0.1338, -2.3107],\n         [-1.3635, -1.8384, -0.6265, -0.8565]]))"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cp = x.clone().contiguous().view(12)\n",
    "x -= 1\n",
    "x_cp, x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-saturn",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### gather\n",
    "`torch.gather(input, dim, index, out=None)`<br>\n",
    "官方定义：沿给定轴dim，将输入索引张量index指定位置的值进行聚合。<br>\n",
    "通俗理解：给定轴dim，在input中，根据index指定的下标，选择元素重组成一个新的tensor，最后输出的out与index的size是一样的。<br>\n",
    "\n",
    "对一个3维张量，输出可以定义为<br>\n",
    "\n",
    "```\n",
    "out[i][j][k] = tensor[index[i][j][k]][j][k] # dim=0\n",
    "out[i][j][k] = tensor[i][index[i][j][k]][k] # dim=1\n",
    "out[i][j][k] = tensor[i][j][index[i][j][k]] # dim=3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "applicable-number",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[0.9000, 0.0000, 0.0000],\n         [0.0000, 0.6000, 0.0000],\n         [0.0000, 0.7000, 0.0000]]),\n tensor([0, 1, 1]))"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_input = torch.tensor([[0.9, 0, 0], [0, 0.6, 0],[0, 0.7, 0]])\n",
    "index = torch.tensor([0, 1, 1])\n",
    "_input, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "negative-spray",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0],\n        [1],\n        [1]])"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cordless-jefferson",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.9000],\n        [0.6000],\n        [0.7000]])"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_input.gather(dim=1, index=index.view(-1, 1))\n",
    "\n",
    "# dim=1，表示的是在第二维度上操作。\n",
    "# 在index中，[0]表示第一行对应元素的下标，即[0.9]\n",
    "#           [1]表示第二行对应元素的下标，即[0.6]\n",
    "#           [1]表示第三行对应元素的下标，即[0.7]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-telescope",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 广播机制\n",
    "当我们对两个形状不同的Tensor按元素运算时，可能会触发`广播(broadcasting)机制`。 <br>\n",
    "先适当复制元素使这两个Tensor形状相同后再按元素运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "satisfactory-airplane",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[1, 2]]),\n tensor([[1],\n         [2],\n         [3]]),\n tensor([[2, 3],\n         [3, 4],\n         [4, 5]]))"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x 中第一行的2个 元素被广播(复制)到了第二行和第三行\n",
    "# y 中第一列的3个元素被广播(复制)到 了第二列\n",
    "x = torch.arange(1, 3).view(1, 2)\n",
    "y = torch.arange(1, 4).view(3, 1)\n",
    "x, y, x+y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-uncertainty",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Tensor和NumPy相互转换\n",
    "+ `numpy()`和`from_numpy()` <br>\n",
    "这两个函数所产生的的Tensor和NumPy中的数组共享相同的内存(所以他们之间的转换很快)，改变其中一个时另一个也会改变!\n",
    "+ `torch.tensor()` <br>\n",
    "进行**数据拷贝**，所以返回的Tensor和原来 的数据不再共享内存。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-phone",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Tensor转NumPy数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "complicated-paintball",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([1., 1., 1.]), array([1., 1., 1.], dtype=float32))"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3)\n",
    "b = a.numpy()\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "accepted-jumping",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([2., 2., 2.]), array([2., 2., 2.], dtype=float32))"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a += 1\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "attempted-magnitude",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([3., 3., 3.]), array([3., 3., 3.], dtype=float32))"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b += 1\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-plenty",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### NumPy数组转 Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "otherwise-worship",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(array([1., 1., 1.]), tensor([1., 1., 1.], dtype=torch.float64))"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones(3)\n",
    "b = torch.from_numpy(a)\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "comparable-thanks",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(array([2., 2., 2.]), tensor([2., 2., 2.], dtype=torch.float64))"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a += 1\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "inner-parliament",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(array([3., 3., 3.]), tensor([3., 3., 3.], dtype=torch.float64))"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b += 1\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "valued-pavilion",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(array([4., 4., 4.]), tensor([3., 3., 3.], dtype=torch.float64))"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用torch.tensor()将NumPy数组转换成Tensor(不再共享内存)\n",
    "c = torch.tensor(a)\n",
    "a += 1\n",
    "a, c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-plastic",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Tensor on GPU\n",
    "+ `to()`<br>\n",
    "将Tensor在CPU和GPU(需要硬件支持)之间相互移动。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-manor",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 自动求梯度\n",
    "+ `autograd 包`<br>\n",
    "根据输入和**前向传播**过程自动构建计算图，并执行**反向传播**。\n",
    "+ `Tensor`是autograd包的核心类<br>\n",
    "将其属性`.requires_grad`设置为True，它将开始追踪在其上的所有操作(这样就可以利用链式法则进行梯度传播了)。<br>\n",
    "完成计算后，可以调用`.backward()`来完成所有梯度计算。此Tensor的梯度将累积到.grad属性中。<br>\n",
    "如果不想要被继续追踪，可以调用`.detach()`将其从追踪记录中分离出来，这样就可以防止将来的计算被追踪，这样梯度就传不过去了。<br>\n",
    "此外，还可以用`with torch.no_grad()`将不想被追踪的操作代码块包裹起来，这种方法在评估模型的时候很常用，因为在评估模型时，我们并不需要计算 可训练参数(requires_grad=True)的梯度。\n",
    "+ `Function`是另外一个很重要的类。<br>\n",
    "Tensor和Function互相结合就可以构建一个记录有整个计算过程的**有向无环图(DAG)**。<br>\n",
    "每个Tensor都有一个.grad_fn属性，该属性即创建该Tensor的Function, 就是说该Tensor是不是通过某些运算得到的，若是，则grad_fn返回一个与这些运算相关的对象，否则是None。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-essence",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "institutional-military",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[1., 1.],\n         [1., 1.]], requires_grad=True),\n None)"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个Tensor并设置requires_grad=True:\n",
    "# x是直接创建的，所以它没有grad_fn\n",
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "x, x.grad_fn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "deadly-chapel",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[3., 3.],\n         [3., 3.]], grad_fn=<AddBackward0>),\n <AddBackward0 at 0x13503b2e8>)"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y 是通过一个加法操作创建的，所以它有一个为<AddBackward>的grad_fn\n",
    "y = x + 2\n",
    "y, y.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "pleasant-military",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[27., 27.],\n         [27., 27.]], grad_fn=<MulBackward0>),\n tensor(27., grad_fn=<MeanBackward0>))"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = y * y * 3 \n",
    "out = z.mean()\n",
    "z, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "approved-happiness",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过.requires_grad_()来用in-place的方式改变requires_grad属性\n",
    "a = torch.randn(2, 2)\n",
    "a = ((a * 3) / (a - 1))\n",
    "a.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "vulnerable-compound",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.requires_grad_(True)\n",
    "a.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "commercial-house",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<SumBackward0 at 0x13503b6d8>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = (a * a).sum()\n",
    "b.grad_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-malaysia",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### 梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "healthy-teens",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[4.5000, 4.5000],\n        [4.5000, 4.5000]])"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "y = x + 2\n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "out.backward()  # 等价于 out.backward(torch.tensor(1.))\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-shell",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "令out为o，因为\n",
    "$$\n",
    "O = \\frac 1 4 \\sum_i^4 z_i = \\frac 1 4 \\sum_i^4 3y_i^2 = \\frac 1 4 \\sum_i^4 3(x_i+2)^2\n",
    "$$\n",
    "所以<br>\n",
    "$$\n",
    "\\frac{\\partial{O}}{\\partial{x_i}}|_{x_i=1} = \\frac 9 2 = 4.5\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "roman-circuit",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[5.5000, 5.5000],\n        [5.5000, 5.5000]])"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 注意grad是累加的\n",
    "out2 = x.sum()\n",
    "out2.backward()      # 梯度未清零，累加梯度\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "minute-deployment",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 1.],\n        [1., 1.]])"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out3 = x.sum()\n",
    "x.grad.data.zero_()\n",
    "out3.backward()      # 梯度清零后，x的梯度为1\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-construction",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### 反向传播\n",
    "`y.backward()`<br>\n",
    "+ 如果 $y$ 是**标量**，则不需要为backward()传入任何参数。<br>\n",
    "+ 如果 $y$ 是**向量**，需要传入一个与y同形的Tensor。<br>\n",
    "这样为了避免向量(甚至更高维张量) 对张量求导，因此转换成标量对张量进行求导。<br>\n",
    "`不允许张量对张量求导`，只允许标量对张量求导，求导结果是和自变量同形的张量。<br>\n",
    "必要时我们要把张量通过将所有张量的元素`加权求和`的方式转换为标量。<br>\n",
    "\n",
    "假设 $𝒚$ 由自变量 $𝒙$ 计算而来，$𝒘$ 是和 $𝒚$ 同形的张量则 $𝐲. 𝐛𝐚𝐜𝐤𝐰𝐚𝐫𝐝(𝒘)$ 的含义是: <br>\n",
    "先计算 $𝒍$ = 𝐭𝐨𝐫𝐜𝐡.𝐬𝐮𝐦($𝒚$ ∗ $𝒘$)，因此 𝒍 是一个标量，然后我们再求 𝒍 对自变量 𝒙 的导数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "clean-overall",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([1., 2., 3., 4.], requires_grad=True),\n tensor([2., 4., 6., 8.], grad_fn=<MulBackward0>),\n tensor([[2., 4.],\n         [6., 8.]], grad_fn=<ViewBackward>))"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0, 4.0], requires_grad=True)\n",
    "y = 2 * x\n",
    "z = y.view(2, 2)\n",
    "x, y, z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-million",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "此时 𝒛 不是一个标量，所以在调用backward()时需要传入一个和 𝒛 同形的权重向量进行加权求和来得到一个标量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "governmental-today",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([2.0000, 0.2000, 0.0200, 0.0020])"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = torch.tensor([[1.0, 0.1], [0.01, 0.001]], dtype=torch.float) \n",
    "z.backward(v)\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-audience",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### .detach()和.data\n",
    "\n",
    "https://zhuanlan.zhihu.com/p/67184419"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "demographic-latter",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
