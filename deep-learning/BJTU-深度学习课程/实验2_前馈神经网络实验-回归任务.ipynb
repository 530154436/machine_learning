{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "automatic-superintendent",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.utils.data as Data\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-engineer",
   "metadata": {},
   "source": [
    "### 回归任务\n",
    "#### 手动生成的数据集\n",
    "+ 生成单个数据集。\n",
    "+ 数据集的大小为10000且训练集大小为7000，测试集大小为3000。\n",
    "+ 数据集的样本特征维度p为500，且服从如下的高维线性函数: $y = 0.028 + \\sum_{i=1}^p0.0056x_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "veterinary-robertson",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: torch.Size([7000, 500]) torch.Size([7000])\n",
      "test : torch.Size([3000, 500]) torch.Size([3000])\n"
     ]
    }
   ],
   "source": [
    "torch.random.manual_seed(1)\n",
    "\n",
    "p = 500\n",
    "x_train = torch.randn((7000, p))\n",
    "y_train = 0.028 + 0.0056 * torch.sum(x_train, dim=1)\n",
    "\n",
    "x_test = torch.randn((3000, p))\n",
    "y_test = 0.028 + 0.0056 * torch.sum(x_test, dim=1)\n",
    "\n",
    "print('train:', x_train.shape, y_train.shape)\n",
    "print('test :', x_test.shape, y_test.shape)\n",
    "\n",
    "# 构造数据集\n",
    "train_set = Data.TensorDataset(x_train, y_train)\n",
    "test_set = Data.TensorDataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c188092f",
   "metadata": {},
   "source": [
    "#### 手动实现前馈神经网络\n",
    "分析实验结果并绘制训练集和测试集的loss曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "appointed-sustainability",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4261/3414944646.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.where(torch.tensor(x>=0), x, torch.zeros(x.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train_loss 0.015222, test_loss  0.013972\n",
      "epoch 1, train_loss 0.012867, test_loss  0.011811\n",
      "epoch 2, train_loss 0.010321, test_loss  0.009308\n",
      "epoch 3, train_loss 0.007515, test_loss  0.006703\n",
      "epoch 4, train_loss 0.004932, test_loss  0.004521\n",
      "epoch 5, train_loss 0.003063, test_loss  0.003057\n",
      "epoch 6, train_loss 0.001962, test_loss  0.002209\n",
      "epoch 7, train_loss 0.001381, test_loss  0.001742\n",
      "epoch 8, train_loss 0.001074, test_loss  0.001478\n",
      "epoch 9, train_loss 0.000899, test_loss  0.001321\n",
      "epoch 10, train_loss 0.000789, test_loss  0.001222\n",
      "epoch 11, train_loss 0.000714, test_loss  0.001155\n",
      "epoch 12, train_loss 0.000658, test_loss  0.001108\n",
      "epoch 13, train_loss 0.000613, test_loss  0.001072\n",
      "epoch 14, train_loss 0.000576, test_loss  0.001044\n",
      "epoch 15, train_loss 0.000544, test_loss  0.001021\n",
      "epoch 16, train_loss 0.000515, test_loss  0.001002\n",
      "epoch 17, train_loss 0.000490, test_loss  0.000985\n",
      "epoch 18, train_loss 0.000467, test_loss  0.000970\n",
      "epoch 19, train_loss 0.000445, test_loss  0.000957\n",
      "epoch 20, train_loss 0.000425, test_loss  0.000945\n",
      "epoch 21, train_loss 0.000407, test_loss  0.000934\n",
      "epoch 22, train_loss 0.000390, test_loss  0.000924\n",
      "epoch 23, train_loss 0.000374, test_loss  0.000915\n",
      "epoch 24, train_loss 0.000358, test_loss  0.000906\n",
      "epoch 25, train_loss 0.000344, test_loss  0.000898\n",
      "epoch 26, train_loss 0.000331, test_loss  0.000890\n",
      "epoch 27, train_loss 0.000318, test_loss  0.000882\n",
      "epoch 28, train_loss 0.000306, test_loss  0.000876\n",
      "epoch 29, train_loss 0.000295, test_loss  0.000869\n",
      "epoch 30, train_loss 0.000284, test_loss  0.000863\n",
      "epoch 31, train_loss 0.000274, test_loss  0.000857\n",
      "epoch 32, train_loss 0.000265, test_loss  0.000851\n",
      "epoch 33, train_loss 0.000255, test_loss  0.000846\n",
      "epoch 34, train_loss 0.000247, test_loss  0.000841\n",
      "epoch 35, train_loss 0.000238, test_loss  0.000836\n",
      "epoch 36, train_loss 0.000230, test_loss  0.000831\n",
      "epoch 37, train_loss 0.000223, test_loss  0.000827\n",
      "epoch 38, train_loss 0.000216, test_loss  0.000822\n",
      "epoch 39, train_loss 0.000209, test_loss  0.000818\n",
      "epoch 40, train_loss 0.000202, test_loss  0.000814\n",
      "epoch 41, train_loss 0.000196, test_loss  0.000810\n",
      "epoch 42, train_loss 0.000190, test_loss  0.000807\n",
      "epoch 43, train_loss 0.000184, test_loss  0.000803\n",
      "epoch 44, train_loss 0.000179, test_loss  0.000800\n",
      "epoch 45, train_loss 0.000173, test_loss  0.000796\n",
      "epoch 46, train_loss 0.000168, test_loss  0.000793\n",
      "epoch 47, train_loss 0.000163, test_loss  0.000790\n",
      "epoch 48, train_loss 0.000159, test_loss  0.000787\n",
      "epoch 49, train_loss 0.000154, test_loss  0.000784\n"
     ]
    }
   ],
   "source": [
    "def data_iter(x: torch.Tensor, y: torch.Tensor, batch_size: int=8,\n",
    "              seed=1, shuffle=True):\n",
    "    \"\"\" 数据集生成器 \"\"\"\n",
    "\n",
    "    num_samples = x.shape[0]\n",
    "    indices = list(range(num_samples))\n",
    "    if shuffle:\n",
    "        random.seed(seed)\n",
    "        random.shuffle(indices)\n",
    "\n",
    "    # 构造小批次数据集\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "\n",
    "        # 选取的该批次内的行索引\n",
    "        j = torch.tensor(indices[i: min(i+batch_size, num_samples)])\n",
    "\n",
    "        yield x.index_select(dim=0, index=j), y.index_select(0, j)\n",
    "\n",
    "\n",
    "def sgd(lr, *params):\n",
    "    \"\"\"\n",
    "    优化器-梯度下降\n",
    "    :param lr:          学习率\n",
    "    :param params:      参数列表\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    for param in params:\n",
    "        # 注意这里更改param时用的param.data\n",
    "        param.data -= lr * param.grad\n",
    "\n",
    "def mse(y_hat: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    均方误差损失函数(MSE)\n",
    "    :param y_hat:   预测值\n",
    "    :param y_true:  真实值\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # train_loss 很低, 但 test_loss 不降, 原因是 y_hat 与 y_true 的形状不一致!!!!\n",
    "    y_hat = y_hat.view(y_true.size())\n",
    "    return torch.mean(torch.square(y_hat - y_true))\n",
    "\n",
    "\n",
    "def tanh(x: torch.Tensor):\n",
    "    \"\"\"\n",
    "    双曲正切\n",
    "    :param x:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return (torch.exp(x)-torch.exp(-x))/(torch.exp(x)+torch.exp(-x))\n",
    "\n",
    "\n",
    "def leak_relu(x: torch.Tensor, gamma=0.2):\n",
    "    \"\"\"\n",
    "    带泄露修正线性单元\n",
    "    :param x:\n",
    "    :param gamma:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    x = torch.where(torch.tensor(x>=0), x, x * gamma)\n",
    "    return x\n",
    "\n",
    "def relu(x: torch.Tensor):\n",
    "    \"\"\"\n",
    "    线性单元\n",
    "    :param x:\n",
    "    :param gamma:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    x = torch.where(torch.tensor(x>=0), x, torch.zeros(x.size()))\n",
    "    return x\n",
    "\n",
    "def neural_net(x: torch.Tensor, *params):\n",
    "    \"\"\"\n",
    "    前馈神经网络\n",
    "    :param x:       特征\n",
    "    :param params:  模型参数\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    w1, b1, w2, b2 = params\n",
    "    # hidden = tanh(torch.mm(x, w1) + b1)\n",
    "    # hidden = leak_relu(torch.mm(x, w1) + b1)\n",
    "    hidden = relu(torch.matmul(x, w1) + b1)\n",
    "    return torch.matmul(hidden, w2) + b2\n",
    "\n",
    "\n",
    "def evaluate_loss(data_iter, net, loss_fn, *params):\n",
    "    \"\"\"\n",
    "    返回测试集的loss\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    test_l_sum, n = 0.0, 0\n",
    "    for x, y_true in data_iter:\n",
    "\n",
    "        y_hat = net(x, *params)\n",
    "        y_hat = y_hat.view(y_true.size())\n",
    "\n",
    "        test_l_sum += loss_fn(y_hat, y_true)\n",
    "        n += 1\n",
    "\n",
    "    return test_l_sum / n\n",
    "\n",
    "\n",
    "# 参数配置\n",
    "num_inputs = x_train.shape[1]\n",
    "num_hiddens = 256\n",
    "num_outputs = 1\n",
    "\n",
    "batch_size = 256\n",
    "num_epochs = 50\n",
    "lr = 0.1\n",
    "net = neural_net\n",
    "loss = mse\n",
    "\n",
    "# 模型训练 w = [w_0, ..., w_n]\n",
    "w1 = torch.tensor(np.random.normal(0, 0.01, (num_inputs, num_hiddens)),\n",
    "                  dtype=torch.float32)\n",
    "b1 = torch.zeros(num_hiddens, dtype=torch.float32)\n",
    "w2 = torch.tensor(np.random.normal(0, 0.01, (num_hiddens, num_outputs)),\n",
    "                  dtype=torch.float32)\n",
    "b2 = torch.zeros(num_outputs, dtype=torch.float32)\n",
    "\n",
    "params = (w1, b1, w2, b2)\n",
    "for param in params:\n",
    "    param.requires_grad_(requires_grad=True)\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # 读取数据集\n",
    "    iter_train = data_iter(x_train, y_train, batch_size=batch_size)\n",
    "    iter_test = data_iter(x_test, y_test, batch_size=batch_size)\n",
    "\n",
    "    # 一批次的训练数据\n",
    "    train_l_sum, n = 0.0, 0\n",
    "    for X, y_true in iter_train:\n",
    "\n",
    "        # 模型预测值\n",
    "        y_hat = net(X, *params)\n",
    "\n",
    "        # 损失值\n",
    "        # (batch_size, 1) => (batch_size, )\n",
    "        l = loss(y_hat, y_true)\n",
    "\n",
    "        # 反向传播\n",
    "        l.backward()\n",
    "\n",
    "        # 随机梯度下降\n",
    "        sgd(lr, *params)\n",
    "\n",
    "        # 梯度置零\n",
    "        for param in params:\n",
    "            param.grad.data.zero_()\n",
    "\n",
    "        train_l_sum += l\n",
    "        n += 1\n",
    "\n",
    "    train_l = train_l_sum / n\n",
    "    test_l = evaluate_loss(iter_test, net, loss, *params)\n",
    "\n",
    "    train_loss.append(train_l.item())\n",
    "    test_loss.append(test_l.item())\n",
    "    print('epoch %d, train_loss %f, test_loss % f' % (epoch, train_l, test_l))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d36a02b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x432 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_loss(train_loss_list, test_loss_list, info=''):\n",
    "    \"\"\"\n",
    "    绘制 训练集和测试集正确率、损失值 的图形\n",
    "    \"\"\"\n",
    "    x = np.linspace(0, len(train_loss_list), len(train_loss_list))\n",
    "    fig, ax1 = plt.subplots(1)\n",
    "    fig.set_size_inches(10, 6)\n",
    "    if info:\n",
    "        info = info + ' '\n",
    "\n",
    "    ax1.plot(x, train_loss_list, 'b-', label=\"train_loss\", lw=1)\n",
    "    ax1.plot(x, test_loss_list, 'r-', label=\"test_loss\", lw=1)\n",
    "    ax1.set_title(info + 'Loss')\n",
    "    ax1.legend(loc='best', frameon=False)\n",
    "    ax1.set_xlabel(\"epoch\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_loss(train_loss, test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d762f47",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### torch.nn实现前馈神经网络\n",
    "分析实验结果并绘制训练集和测试集的loss曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3fb0d5cf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(data_loader: Data.DataLoader, net: nn.Module,\n",
    "                loss_func, optimizer: torch.optim.Optimizer,\n",
    "                device='cpu'):\n",
    "    \"\"\"\n",
    "    训练迭代一次\n",
    "    :param data_loader: 生成器 (x, y)\n",
    "    :param net:         模型\n",
    "    :param loss_func:   损失函数\n",
    "    :param optimizer:   优化器\n",
    "    :param device:      设备\n",
    "    :return:    loss, acc\n",
    "    \"\"\"\n",
    "    net.train()\n",
    "    train_batch_num = len(data_loader)\n",
    "\n",
    "    # 一次迭代中的 Loss、正确样本数、总样本数\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_num, (x, y_true) in enumerate(data_loader):\n",
    "\n",
    "        # 将数据放入指定的设备\n",
    "        x = x.to(device).float()\n",
    "\n",
    "        y_hat: torch.Tensor = net(x)\n",
    "        y_hat: torch.Tensor = y_hat.view(-1)\n",
    "\n",
    "        y_true = y_true.to(device).float()\n",
    "        y_true: torch.Tensor = y_true.view(-1)\n",
    "\n",
    "        # 计算损失\n",
    "        loss = loss_func(y_hat, y_true)\n",
    "\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad() #清空梯度\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    loss = total_loss / train_batch_num\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def test_epoch(data_loader: Data.DataLoader,\n",
    "               net: nn.Module, loss_func, device='cpu'):\n",
    "    \"\"\"\n",
    "    测试函数迭代一次\n",
    "    :param data_loader: 生成器 (x, y)\n",
    "    :param net:         模型\n",
    "    :param loss_func:   损失函数\n",
    "    :param device:      设备\n",
    "    :return:    loss, acc\n",
    "    \"\"\"\n",
    "    net.eval()\n",
    "    train_batch_num = len(data_loader)\n",
    "\n",
    "    # 一次迭代中的 Loss\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch_num, (x, y_true) in enumerate(data_loader):\n",
    "\n",
    "            # 将数据放入指定的设备\n",
    "            x = x.to(device).float()\n",
    "\n",
    "            y_hat: torch.Tensor = net(x)\n",
    "            y_hat: torch.Tensor = y_hat.view(-1)\n",
    "\n",
    "            y_true = y_true.to(device).float()\n",
    "            y_true: torch.Tensor = y_true.view(-1)\n",
    "\n",
    "            # 计算损失\n",
    "            loss = loss_func(y_hat, y_true)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    loss = total_loss / train_batch_num\n",
    "    return loss\n",
    "\n",
    "\n",
    "def plot_loss(train_loss_list, test_loss_list, info=''):\n",
    "    \"\"\"\n",
    "    绘制 训练集和测试集正确率、损失值 的图形\n",
    "    \"\"\"\n",
    "    x = np.linspace(0, len(train_loss_list), len(train_loss_list))\n",
    "    fig, ax1 = plt.subplots(1)\n",
    "    fig.set_size_inches(10, 6)\n",
    "    if info:\n",
    "        info = info + ' '\n",
    "\n",
    "    ax1.plot(x, train_loss_list, 'b-', label=\"train_loss\", lw=1)\n",
    "    ax1.plot(x, test_loss_list, 'r-', label=\"test_loss\", lw=1)\n",
    "    ax1.set_title(info + 'Loss')\n",
    "    ax1.legend(loc='best', frameon=False)\n",
    "    ax1.set_xlabel(\"epoch\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "class TorchNeuron(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size,\n",
    "                 activation=nn.ReLU, num_layers=1, drop_out_rate=0):\n",
    "        super(TorchNeuron, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.activation = activation\n",
    "        self.drop_out_rate = drop_out_rate\n",
    "\n",
    "        self.linear = nn.Sequential(*self.create_linear_layers())\n",
    "\n",
    "        for param in self.linear.parameters():\n",
    "            nn.init.normal_(param, std=0.01)\n",
    "\n",
    "    def create_linear_layers(self) -> Tuple[nn.Module]:\n",
    "        \"\"\"\n",
    "        创建层\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        modules = [\n",
    "            nn.Linear(self.input_size, self.hidden_size),\n",
    "            self.activation(),\n",
    "            nn.Dropout(self.drop_out_rate),\n",
    "        ]\n",
    "        for i in range(self.num_layers - 1):\n",
    "            modules.append(nn.Linear(self.hidden_size, self.hidden_size))\n",
    "            modules.append(self.activation())\n",
    "            modules.append(nn.Dropout(self.drop_out_rate))\n",
    "        modules.append(nn.Linear(self.hidden_size, self.output_size))\n",
    "        return tuple(modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchNeuron(\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=500, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "epoch 1, train_loss 0.015454, test_loss 0.014022\n",
      "epoch 2, train_loss 0.013093, test_loss 0.012169\n",
      "epoch 3, train_loss 0.010715, test_loss 0.009805\n",
      "epoch 4, train_loss 0.007964, test_loss 0.007217\n",
      "epoch 5, train_loss 0.005353, test_loss 0.004954\n",
      "epoch 6, train_loss 0.003373, test_loss 0.003374\n",
      "epoch 7, train_loss 0.002139, test_loss 0.002401\n",
      "epoch 8, train_loss 0.001486, test_loss 0.001857\n",
      "epoch 9, train_loss 0.001131, test_loss 0.001536\n",
      "epoch 10, train_loss 0.000938, test_loss 0.001365\n",
      "epoch 11, train_loss 0.000811, test_loss 0.001266\n",
      "epoch 12, train_loss 0.000729, test_loss 0.001176\n",
      "epoch 13, train_loss 0.000670, test_loss 0.001116\n",
      "epoch 14, train_loss 0.000620, test_loss 0.001076\n",
      "epoch 15, train_loss 0.000583, test_loss 0.001053\n",
      "epoch 16, train_loss 0.000553, test_loss 0.001031\n",
      "epoch 17, train_loss 0.000524, test_loss 0.001008\n",
      "epoch 18, train_loss 0.000497, test_loss 0.000986\n",
      "epoch 19, train_loss 0.000472, test_loss 0.000977\n",
      "epoch 20, train_loss 0.000448, test_loss 0.000960\n",
      "epoch 21, train_loss 0.000432, test_loss 0.000948\n",
      "epoch 22, train_loss 0.000412, test_loss 0.000938\n",
      "epoch 23, train_loss 0.000393, test_loss 0.000927\n",
      "epoch 24, train_loss 0.000377, test_loss 0.000919\n",
      "epoch 25, train_loss 0.000363, test_loss 0.000907\n",
      "epoch 26, train_loss 0.000347, test_loss 0.000898\n",
      "epoch 27, train_loss 0.000337, test_loss 0.000894\n",
      "epoch 28, train_loss 0.000322, test_loss 0.000882\n",
      "epoch 29, train_loss 0.000308, test_loss 0.000877\n",
      "epoch 30, train_loss 0.000297, test_loss 0.000864\n",
      "epoch 31, train_loss 0.000286, test_loss 0.000863\n",
      "epoch 32, train_loss 0.000277, test_loss 0.000861\n",
      "epoch 33, train_loss 0.000266, test_loss 0.000847\n",
      "epoch 34, train_loss 0.000260, test_loss 0.000845\n",
      "epoch 35, train_loss 0.000248, test_loss 0.000841\n",
      "epoch 36, train_loss 0.000241, test_loss 0.000837\n",
      "epoch 37, train_loss 0.000235, test_loss 0.000832\n",
      "epoch 38, train_loss 0.000226, test_loss 0.000825\n",
      "epoch 39, train_loss 0.000218, test_loss 0.000818\n",
      "epoch 40, train_loss 0.000211, test_loss 0.000818\n",
      "epoch 41, train_loss 0.000204, test_loss 0.000814\n",
      "epoch 42, train_loss 0.000199, test_loss 0.000812\n",
      "epoch 43, train_loss 0.000193, test_loss 0.000804\n",
      "epoch 44, train_loss 0.000186, test_loss 0.000801\n",
      "epoch 45, train_loss 0.000180, test_loss 0.000796\n",
      "epoch 46, train_loss 0.000175, test_loss 0.000795\n",
      "epoch 47, train_loss 0.000170, test_loss 0.000790\n",
      "epoch 48, train_loss 0.000164, test_loss 0.000786\n",
      "epoch 49, train_loss 0.000160, test_loss 0.000785\n",
      "epoch 50, train_loss 0.000156, test_loss 0.000784\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 720x432 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 参数配置\n",
    "device = 'cpu'\n",
    "input_size = x_train.shape[1]\n",
    "hidden_size = 256\n",
    "output_size = 1\n",
    "\n",
    "batch_size = 256\n",
    "num_epochs = 50\n",
    "lr = 0.1\n",
    "\n",
    "net = TorchNeuron(input_size, hidden_size, output_size)\n",
    "print(net)\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_loss_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_data_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    test_data_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    train_loss = train_epoch(data_loader=train_data_loader, net=net,\n",
    "                                        loss_func=loss_func, optimizer=optimizer, device=device)\n",
    "    test_loss = test_epoch(data_loader=test_data_loader, net=net,\n",
    "                                     loss_func=loss_func, device=device)\n",
    "\n",
    "    print('epoch %d, train_loss %f, test_loss %f'\n",
    "          % (epoch+1, train_loss, test_loss))\n",
    "\n",
    "    train_loss_list.append(train_loss)\n",
    "    test_loss_list.append(test_loss)\n",
    "\n",
    "plot_loss(train_loss_list, test_loss_list)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "####  10折交叉验证评估实验结果\n",
    "要求除了最终结果外还需以表格的形式展示每折的实验结果"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchNeuron(\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=500, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "epoch 1, train_loss 0.015675, test_loss 0.014335\n",
      "epoch 2, train_loss 0.014316, test_loss 0.013209\n",
      "epoch 3, train_loss 0.012602, test_loss 0.010761\n",
      "epoch 4, train_loss 0.010252, test_loss 0.008072\n",
      "epoch 5, train_loss 0.007547, test_loss 0.005443\n",
      "epoch 6, train_loss 0.005385, test_loss 0.003459\n",
      "epoch 7, train_loss 0.003865, test_loss 0.002333\n",
      "epoch 8, train_loss 0.003150, test_loss 0.001743\n",
      "epoch 9, train_loss 0.002705, test_loss 0.001402\n",
      "epoch 10, train_loss 0.002458, test_loss 0.001206\n",
      "epoch 11, train_loss 0.002329, test_loss 0.001098\n",
      "epoch 12, train_loss 0.002031, test_loss 0.000943\n",
      "epoch 13, train_loss 0.002061, test_loss 0.000886\n",
      "epoch 14, train_loss 0.001859, test_loss 0.000842\n",
      "epoch 15, train_loss 0.001799, test_loss 0.000769\n",
      "epoch 16, train_loss 0.001760, test_loss 0.000733\n",
      "epoch 17, train_loss 0.001620, test_loss 0.000693\n",
      "epoch 18, train_loss 0.001646, test_loss 0.000661\n",
      "epoch 19, train_loss 0.001545, test_loss 0.000638\n",
      "epoch 20, train_loss 0.001518, test_loss 0.000658\n",
      "epoch 21, train_loss 0.001428, test_loss 0.000595\n",
      "epoch 22, train_loss 0.001372, test_loss 0.000560\n",
      "epoch 23, train_loss 0.001326, test_loss 0.000553\n",
      "epoch 24, train_loss 0.001309, test_loss 0.000524\n",
      "epoch 25, train_loss 0.001293, test_loss 0.000509\n",
      "epoch 26, train_loss 0.001216, test_loss 0.000502\n",
      "epoch 27, train_loss 0.001198, test_loss 0.000489\n",
      "epoch 28, train_loss 0.001166, test_loss 0.000477\n",
      "epoch 29, train_loss 0.001131, test_loss 0.000464\n",
      "epoch 30, train_loss 0.001135, test_loss 0.000445\n",
      "epoch 31, train_loss 0.001075, test_loss 0.000412\n",
      "epoch 32, train_loss 0.001140, test_loss 0.000413\n",
      "epoch 33, train_loss 0.001065, test_loss 0.000403\n",
      "epoch 34, train_loss 0.001023, test_loss 0.000399\n",
      "epoch 35, train_loss 0.001044, test_loss 0.000391\n",
      "epoch 36, train_loss 0.001003, test_loss 0.000372\n",
      "epoch 37, train_loss 0.001000, test_loss 0.000370\n",
      "epoch 38, train_loss 0.000964, test_loss 0.000355\n",
      "epoch 39, train_loss 0.000972, test_loss 0.000348\n",
      "epoch 40, train_loss 0.000935, test_loss 0.000344\n",
      "epoch 41, train_loss 0.000945, test_loss 0.000332\n",
      "epoch 42, train_loss 0.000897, test_loss 0.000336\n",
      "epoch 43, train_loss 0.000901, test_loss 0.000329\n",
      "epoch 44, train_loss 0.000883, test_loss 0.000320\n",
      "epoch 45, train_loss 0.000869, test_loss 0.000311\n",
      "epoch 46, train_loss 0.000843, test_loss 0.000311\n",
      "epoch 47, train_loss 0.000825, test_loss 0.000301\n",
      "epoch 48, train_loss 0.000832, test_loss 0.000296\n",
      "epoch 49, train_loss 0.000819, test_loss 0.000293\n",
      "epoch 50, train_loss 0.000802, test_loss 0.000289\n",
      "TorchNeuron(\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=500, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "epoch 1, train_loss 0.015915, test_loss 0.015687\n",
      "epoch 2, train_loss 0.014265, test_loss 0.014217\n",
      "epoch 3, train_loss 0.012536, test_loss 0.012145\n",
      "epoch 4, train_loss 0.010146, test_loss 0.009240\n",
      "epoch 5, train_loss 0.007520, test_loss 0.006359\n",
      "epoch 6, train_loss 0.005325, test_loss 0.004121\n",
      "epoch 7, train_loss 0.004036, test_loss 0.002813\n",
      "epoch 8, train_loss 0.003242, test_loss 0.002016\n",
      "epoch 9, train_loss 0.002769, test_loss 0.001600\n",
      "epoch 10, train_loss 0.002505, test_loss 0.001356\n",
      "epoch 11, train_loss 0.002328, test_loss 0.001178\n",
      "epoch 12, train_loss 0.002158, test_loss 0.001087\n",
      "epoch 13, train_loss 0.002053, test_loss 0.001001\n",
      "epoch 14, train_loss 0.001871, test_loss 0.000929\n",
      "epoch 15, train_loss 0.001812, test_loss 0.000885\n",
      "epoch 16, train_loss 0.001757, test_loss 0.000847\n",
      "epoch 17, train_loss 0.001722, test_loss 0.000761\n",
      "epoch 18, train_loss 0.001576, test_loss 0.000731\n",
      "epoch 19, train_loss 0.001575, test_loss 0.000771\n",
      "epoch 20, train_loss 0.001479, test_loss 0.000702\n",
      "epoch 21, train_loss 0.001420, test_loss 0.000661\n",
      "epoch 22, train_loss 0.001419, test_loss 0.000623\n",
      "epoch 23, train_loss 0.001312, test_loss 0.000675\n",
      "epoch 24, train_loss 0.001290, test_loss 0.000575\n",
      "epoch 25, train_loss 0.001242, test_loss 0.000575\n",
      "epoch 26, train_loss 0.001238, test_loss 0.000567\n",
      "epoch 27, train_loss 0.001218, test_loss 0.000551\n",
      "epoch 28, train_loss 0.001168, test_loss 0.000558\n",
      "epoch 29, train_loss 0.001183, test_loss 0.000503\n",
      "epoch 30, train_loss 0.001148, test_loss 0.000502\n",
      "epoch 31, train_loss 0.001106, test_loss 0.000484\n",
      "epoch 32, train_loss 0.001102, test_loss 0.000460\n",
      "epoch 33, train_loss 0.001060, test_loss 0.000444\n",
      "epoch 34, train_loss 0.001035, test_loss 0.000436\n",
      "epoch 35, train_loss 0.001039, test_loss 0.000431\n",
      "epoch 36, train_loss 0.000991, test_loss 0.000430\n",
      "epoch 37, train_loss 0.000986, test_loss 0.000407\n",
      "epoch 38, train_loss 0.000967, test_loss 0.000400\n",
      "epoch 39, train_loss 0.000952, test_loss 0.000403\n",
      "epoch 40, train_loss 0.000925, test_loss 0.000397\n",
      "epoch 41, train_loss 0.000943, test_loss 0.000384\n",
      "epoch 42, train_loss 0.000917, test_loss 0.000374\n",
      "epoch 43, train_loss 0.000915, test_loss 0.000374\n",
      "epoch 44, train_loss 0.000882, test_loss 0.000360\n",
      "epoch 45, train_loss 0.000875, test_loss 0.000346\n",
      "epoch 46, train_loss 0.000879, test_loss 0.000342\n",
      "epoch 47, train_loss 0.000838, test_loss 0.000329\n",
      "epoch 48, train_loss 0.000838, test_loss 0.000335\n",
      "epoch 49, train_loss 0.000853, test_loss 0.000328\n",
      "epoch 50, train_loss 0.000832, test_loss 0.000314\n",
      "TorchNeuron(\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=500, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "epoch 1, train_loss 0.015463, test_loss 0.015138\n",
      "epoch 2, train_loss 0.014191, test_loss 0.013704\n",
      "epoch 3, train_loss 0.012447, test_loss 0.011721\n",
      "epoch 4, train_loss 0.010254, test_loss 0.008924\n",
      "epoch 5, train_loss 0.007565, test_loss 0.006106\n",
      "epoch 6, train_loss 0.005423, test_loss 0.003953\n",
      "epoch 7, train_loss 0.004060, test_loss 0.002715\n",
      "epoch 8, train_loss 0.003356, test_loss 0.001934\n",
      "epoch 9, train_loss 0.002860, test_loss 0.001565\n",
      "epoch 10, train_loss 0.002512, test_loss 0.001302\n",
      "epoch 11, train_loss 0.002244, test_loss 0.001164\n",
      "epoch 12, train_loss 0.002140, test_loss 0.001063\n",
      "epoch 13, train_loss 0.002039, test_loss 0.000984\n",
      "epoch 14, train_loss 0.001919, test_loss 0.000906\n",
      "epoch 15, train_loss 0.001806, test_loss 0.000862\n",
      "epoch 16, train_loss 0.001729, test_loss 0.000805\n",
      "epoch 17, train_loss 0.001677, test_loss 0.000762\n",
      "epoch 18, train_loss 0.001600, test_loss 0.000709\n",
      "epoch 19, train_loss 0.001517, test_loss 0.000688\n",
      "epoch 20, train_loss 0.001500, test_loss 0.000647\n",
      "epoch 21, train_loss 0.001527, test_loss 0.000618\n",
      "epoch 22, train_loss 0.001411, test_loss 0.000615\n",
      "epoch 23, train_loss 0.001348, test_loss 0.000602\n",
      "epoch 24, train_loss 0.001334, test_loss 0.000584\n",
      "epoch 25, train_loss 0.001276, test_loss 0.000546\n",
      "epoch 26, train_loss 0.001248, test_loss 0.000536\n",
      "epoch 27, train_loss 0.001232, test_loss 0.000518\n",
      "epoch 28, train_loss 0.001206, test_loss 0.000491\n",
      "epoch 29, train_loss 0.001168, test_loss 0.000489\n",
      "epoch 30, train_loss 0.001141, test_loss 0.000477\n",
      "epoch 31, train_loss 0.001102, test_loss 0.000456\n",
      "epoch 32, train_loss 0.001081, test_loss 0.000462\n",
      "epoch 33, train_loss 0.001083, test_loss 0.000444\n",
      "epoch 34, train_loss 0.001053, test_loss 0.000436\n",
      "epoch 35, train_loss 0.001013, test_loss 0.000440\n",
      "epoch 36, train_loss 0.001005, test_loss 0.000409\n",
      "epoch 37, train_loss 0.001020, test_loss 0.000392\n",
      "epoch 38, train_loss 0.000973, test_loss 0.000390\n",
      "epoch 39, train_loss 0.000959, test_loss 0.000409\n",
      "epoch 40, train_loss 0.000928, test_loss 0.000367\n",
      "epoch 41, train_loss 0.000917, test_loss 0.000363\n",
      "epoch 42, train_loss 0.000910, test_loss 0.000347\n",
      "epoch 43, train_loss 0.000888, test_loss 0.000358\n",
      "epoch 44, train_loss 0.000897, test_loss 0.000338\n",
      "epoch 45, train_loss 0.000855, test_loss 0.000334\n",
      "epoch 46, train_loss 0.000860, test_loss 0.000329\n",
      "epoch 47, train_loss 0.000839, test_loss 0.000328\n",
      "epoch 48, train_loss 0.000830, test_loss 0.000331\n",
      "epoch 49, train_loss 0.000789, test_loss 0.000324\n",
      "epoch 50, train_loss 0.000825, test_loss 0.000313\n",
      "TorchNeuron(\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=500, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "epoch 1, train_loss 0.015659, test_loss 0.014335\n",
      "epoch 2, train_loss 0.014510, test_loss 0.012936\n",
      "epoch 3, train_loss 0.012757, test_loss 0.011164\n",
      "epoch 4, train_loss 0.010726, test_loss 0.008646\n",
      "epoch 5, train_loss 0.007984, test_loss 0.005904\n",
      "epoch 6, train_loss 0.005531, test_loss 0.003836\n",
      "epoch 7, train_loss 0.004114, test_loss 0.002583\n",
      "epoch 8, train_loss 0.003248, test_loss 0.001929\n",
      "epoch 9, train_loss 0.002803, test_loss 0.001531\n",
      "epoch 10, train_loss 0.002477, test_loss 0.001285\n",
      "epoch 11, train_loss 0.002315, test_loss 0.001145\n",
      "epoch 12, train_loss 0.002103, test_loss 0.001049\n",
      "epoch 13, train_loss 0.001969, test_loss 0.000972\n",
      "epoch 14, train_loss 0.001894, test_loss 0.000915\n",
      "epoch 15, train_loss 0.001834, test_loss 0.000839\n",
      "epoch 16, train_loss 0.001760, test_loss 0.000820\n",
      "epoch 17, train_loss 0.001655, test_loss 0.000764\n",
      "epoch 18, train_loss 0.001606, test_loss 0.000723\n",
      "epoch 19, train_loss 0.001502, test_loss 0.000694\n",
      "epoch 20, train_loss 0.001500, test_loss 0.000672\n",
      "epoch 21, train_loss 0.001419, test_loss 0.000648\n",
      "epoch 22, train_loss 0.001427, test_loss 0.000596\n",
      "epoch 23, train_loss 0.001347, test_loss 0.000582\n",
      "epoch 24, train_loss 0.001271, test_loss 0.000593\n",
      "epoch 25, train_loss 0.001300, test_loss 0.000552\n",
      "epoch 26, train_loss 0.001238, test_loss 0.000532\n",
      "epoch 27, train_loss 0.001185, test_loss 0.000512\n",
      "epoch 28, train_loss 0.001195, test_loss 0.000505\n",
      "epoch 29, train_loss 0.001158, test_loss 0.000550\n",
      "epoch 30, train_loss 0.001149, test_loss 0.000493\n",
      "epoch 31, train_loss 0.001097, test_loss 0.000473\n",
      "epoch 32, train_loss 0.001059, test_loss 0.000455\n",
      "epoch 33, train_loss 0.001058, test_loss 0.000444\n",
      "epoch 34, train_loss 0.000991, test_loss 0.000433\n",
      "epoch 35, train_loss 0.001016, test_loss 0.000426\n",
      "epoch 36, train_loss 0.000996, test_loss 0.000419\n",
      "epoch 37, train_loss 0.000995, test_loss 0.000401\n",
      "epoch 38, train_loss 0.000963, test_loss 0.000394\n",
      "epoch 39, train_loss 0.000944, test_loss 0.000380\n",
      "epoch 40, train_loss 0.000942, test_loss 0.000387\n",
      "epoch 41, train_loss 0.000927, test_loss 0.000369\n",
      "epoch 42, train_loss 0.000916, test_loss 0.000365\n",
      "epoch 43, train_loss 0.000916, test_loss 0.000342\n",
      "epoch 44, train_loss 0.000869, test_loss 0.000342\n",
      "epoch 45, train_loss 0.000873, test_loss 0.000340\n",
      "epoch 46, train_loss 0.000870, test_loss 0.000327\n",
      "epoch 47, train_loss 0.000846, test_loss 0.000319\n",
      "epoch 48, train_loss 0.000810, test_loss 0.000312\n",
      "epoch 49, train_loss 0.000827, test_loss 0.000318\n",
      "epoch 50, train_loss 0.000816, test_loss 0.000307\n",
      "TorchNeuron(\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=500, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "epoch 1, train_loss 0.015235, test_loss 0.015018\n",
      "epoch 2, train_loss 0.014040, test_loss 0.013544\n",
      "epoch 3, train_loss 0.012213, test_loss 0.011321\n",
      "epoch 4, train_loss 0.009947, test_loss 0.008544\n",
      "epoch 5, train_loss 0.007119, test_loss 0.005773\n",
      "epoch 6, train_loss 0.005268, test_loss 0.003766\n",
      "epoch 7, train_loss 0.003950, test_loss 0.002518\n",
      "epoch 8, train_loss 0.003095, test_loss 0.001966\n",
      "epoch 9, train_loss 0.002670, test_loss 0.001537\n",
      "epoch 10, train_loss 0.002508, test_loss 0.001338\n",
      "epoch 11, train_loss 0.002257, test_loss 0.001170\n",
      "epoch 12, train_loss 0.002126, test_loss 0.001058\n",
      "epoch 13, train_loss 0.001987, test_loss 0.000979\n",
      "epoch 14, train_loss 0.001903, test_loss 0.000911\n",
      "epoch 15, train_loss 0.001775, test_loss 0.000860\n",
      "epoch 16, train_loss 0.001748, test_loss 0.000837\n",
      "epoch 17, train_loss 0.001668, test_loss 0.000769\n",
      "epoch 18, train_loss 0.001621, test_loss 0.000742\n",
      "epoch 19, train_loss 0.001532, test_loss 0.000696\n",
      "epoch 20, train_loss 0.001477, test_loss 0.000652\n",
      "epoch 21, train_loss 0.001421, test_loss 0.000638\n",
      "epoch 22, train_loss 0.001398, test_loss 0.000620\n",
      "epoch 23, train_loss 0.001326, test_loss 0.000583\n",
      "epoch 24, train_loss 0.001249, test_loss 0.000578\n",
      "epoch 25, train_loss 0.001330, test_loss 0.000572\n",
      "epoch 26, train_loss 0.001248, test_loss 0.000545\n",
      "epoch 27, train_loss 0.001180, test_loss 0.000547\n",
      "epoch 28, train_loss 0.001180, test_loss 0.000517\n",
      "epoch 29, train_loss 0.001142, test_loss 0.000493\n",
      "epoch 30, train_loss 0.001154, test_loss 0.000473\n",
      "epoch 31, train_loss 0.001127, test_loss 0.000473\n",
      "epoch 32, train_loss 0.001055, test_loss 0.000465\n",
      "epoch 33, train_loss 0.001055, test_loss 0.000451\n",
      "epoch 34, train_loss 0.001062, test_loss 0.000429\n",
      "epoch 35, train_loss 0.000972, test_loss 0.000424\n",
      "epoch 36, train_loss 0.001038, test_loss 0.000397\n",
      "epoch 37, train_loss 0.000969, test_loss 0.000401\n",
      "epoch 38, train_loss 0.000996, test_loss 0.000389\n",
      "epoch 39, train_loss 0.000939, test_loss 0.000375\n",
      "epoch 40, train_loss 0.000924, test_loss 0.000366\n",
      "epoch 41, train_loss 0.000905, test_loss 0.000368\n",
      "epoch 42, train_loss 0.000893, test_loss 0.000348\n",
      "epoch 43, train_loss 0.000855, test_loss 0.000352\n",
      "epoch 44, train_loss 0.000888, test_loss 0.000345\n",
      "epoch 45, train_loss 0.000871, test_loss 0.000337\n",
      "epoch 46, train_loss 0.000835, test_loss 0.000343\n",
      "epoch 47, train_loss 0.000837, test_loss 0.000330\n",
      "epoch 48, train_loss 0.000844, test_loss 0.000331\n",
      "epoch 49, train_loss 0.000798, test_loss 0.000312\n",
      "epoch 50, train_loss 0.000792, test_loss 0.000303\n",
      "TorchNeuron(\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=500, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "epoch 1, train_loss 0.015180, test_loss 0.014337\n",
      "epoch 2, train_loss 0.014017, test_loss 0.012811\n",
      "epoch 3, train_loss 0.012324, test_loss 0.010815\n",
      "epoch 4, train_loss 0.009921, test_loss 0.008198\n",
      "epoch 5, train_loss 0.007271, test_loss 0.005436\n",
      "epoch 6, train_loss 0.005252, test_loss 0.003565\n",
      "epoch 7, train_loss 0.003931, test_loss 0.002440\n",
      "epoch 8, train_loss 0.003136, test_loss 0.001820\n",
      "epoch 9, train_loss 0.002731, test_loss 0.001470\n",
      "epoch 10, train_loss 0.002430, test_loss 0.001260\n",
      "epoch 11, train_loss 0.002257, test_loss 0.001134\n",
      "epoch 12, train_loss 0.002077, test_loss 0.001026\n",
      "epoch 13, train_loss 0.001952, test_loss 0.000954\n",
      "epoch 14, train_loss 0.001923, test_loss 0.000929\n",
      "epoch 15, train_loss 0.001819, test_loss 0.000850\n",
      "epoch 16, train_loss 0.001733, test_loss 0.000817\n",
      "epoch 17, train_loss 0.001647, test_loss 0.000772\n",
      "epoch 18, train_loss 0.001591, test_loss 0.000731\n",
      "epoch 19, train_loss 0.001496, test_loss 0.000696\n",
      "epoch 20, train_loss 0.001515, test_loss 0.000663\n",
      "epoch 21, train_loss 0.001432, test_loss 0.000662\n",
      "epoch 22, train_loss 0.001361, test_loss 0.000611\n",
      "epoch 23, train_loss 0.001310, test_loss 0.000606\n",
      "epoch 24, train_loss 0.001293, test_loss 0.000580\n",
      "epoch 25, train_loss 0.001233, test_loss 0.000555\n",
      "epoch 26, train_loss 0.001252, test_loss 0.000545\n",
      "epoch 27, train_loss 0.001197, test_loss 0.000533\n",
      "epoch 28, train_loss 0.001170, test_loss 0.000520\n",
      "epoch 29, train_loss 0.001161, test_loss 0.000488\n",
      "epoch 30, train_loss 0.001105, test_loss 0.000510\n",
      "epoch 31, train_loss 0.001106, test_loss 0.000466\n",
      "epoch 32, train_loss 0.001060, test_loss 0.000458\n",
      "epoch 33, train_loss 0.001072, test_loss 0.000449\n",
      "epoch 34, train_loss 0.001042, test_loss 0.000438\n",
      "epoch 35, train_loss 0.000980, test_loss 0.000445\n",
      "epoch 36, train_loss 0.000997, test_loss 0.000402\n",
      "epoch 37, train_loss 0.000975, test_loss 0.000392\n",
      "epoch 38, train_loss 0.000981, test_loss 0.000401\n",
      "epoch 39, train_loss 0.000932, test_loss 0.000385\n",
      "epoch 40, train_loss 0.000923, test_loss 0.000362\n",
      "epoch 41, train_loss 0.000897, test_loss 0.000366\n",
      "epoch 42, train_loss 0.000899, test_loss 0.000365\n",
      "epoch 43, train_loss 0.000874, test_loss 0.000366\n",
      "epoch 44, train_loss 0.000875, test_loss 0.000364\n",
      "epoch 45, train_loss 0.000850, test_loss 0.000335\n",
      "epoch 46, train_loss 0.000850, test_loss 0.000341\n",
      "epoch 47, train_loss 0.000835, test_loss 0.000331\n",
      "epoch 48, train_loss 0.000793, test_loss 0.000325\n",
      "epoch 49, train_loss 0.000813, test_loss 0.000320\n",
      "epoch 50, train_loss 0.000789, test_loss 0.000314\n",
      "TorchNeuron(\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=500, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "epoch 1, train_loss 0.015455, test_loss 0.015010\n",
      "epoch 2, train_loss 0.014240, test_loss 0.013838\n",
      "epoch 3, train_loss 0.012602, test_loss 0.011655\n",
      "epoch 4, train_loss 0.010518, test_loss 0.008982\n",
      "epoch 5, train_loss 0.007870, test_loss 0.006184\n",
      "epoch 6, train_loss 0.005553, test_loss 0.004125\n",
      "epoch 7, train_loss 0.004143, test_loss 0.002811\n",
      "epoch 8, train_loss 0.003326, test_loss 0.002002\n",
      "epoch 9, train_loss 0.002864, test_loss 0.001625\n",
      "epoch 10, train_loss 0.002545, test_loss 0.001369\n",
      "epoch 11, train_loss 0.002443, test_loss 0.001226\n",
      "epoch 12, train_loss 0.002126, test_loss 0.001083\n",
      "epoch 13, train_loss 0.002039, test_loss 0.001016\n",
      "epoch 14, train_loss 0.001948, test_loss 0.000922\n",
      "epoch 15, train_loss 0.001854, test_loss 0.000866\n",
      "epoch 16, train_loss 0.001679, test_loss 0.000831\n",
      "epoch 17, train_loss 0.001684, test_loss 0.000765\n",
      "epoch 18, train_loss 0.001580, test_loss 0.000747\n",
      "epoch 19, train_loss 0.001557, test_loss 0.000707\n",
      "epoch 20, train_loss 0.001480, test_loss 0.000738\n",
      "epoch 21, train_loss 0.001435, test_loss 0.000647\n",
      "epoch 22, train_loss 0.001393, test_loss 0.000617\n",
      "epoch 23, train_loss 0.001339, test_loss 0.000623\n",
      "epoch 24, train_loss 0.001339, test_loss 0.000577\n",
      "epoch 25, train_loss 0.001293, test_loss 0.000572\n",
      "epoch 26, train_loss 0.001240, test_loss 0.000556\n",
      "epoch 27, train_loss 0.001235, test_loss 0.000540\n",
      "epoch 28, train_loss 0.001207, test_loss 0.000527\n",
      "epoch 29, train_loss 0.001146, test_loss 0.000506\n",
      "epoch 30, train_loss 0.001137, test_loss 0.000502\n",
      "epoch 31, train_loss 0.001105, test_loss 0.000489\n",
      "epoch 32, train_loss 0.001098, test_loss 0.000458\n",
      "epoch 33, train_loss 0.001073, test_loss 0.000447\n",
      "epoch 34, train_loss 0.001022, test_loss 0.000434\n",
      "epoch 35, train_loss 0.001034, test_loss 0.000421\n",
      "epoch 36, train_loss 0.001010, test_loss 0.000417\n",
      "epoch 37, train_loss 0.000966, test_loss 0.000420\n",
      "epoch 38, train_loss 0.000968, test_loss 0.000409\n",
      "epoch 39, train_loss 0.000938, test_loss 0.000404\n",
      "epoch 40, train_loss 0.000933, test_loss 0.000384\n",
      "epoch 41, train_loss 0.000944, test_loss 0.000398\n",
      "epoch 42, train_loss 0.000921, test_loss 0.000384\n",
      "epoch 43, train_loss 0.000890, test_loss 0.000379\n",
      "epoch 44, train_loss 0.000872, test_loss 0.000362\n",
      "epoch 45, train_loss 0.000865, test_loss 0.000354\n",
      "epoch 46, train_loss 0.000876, test_loss 0.000359\n",
      "epoch 47, train_loss 0.000842, test_loss 0.000345\n",
      "epoch 48, train_loss 0.000806, test_loss 0.000341\n",
      "epoch 49, train_loss 0.000822, test_loss 0.000321\n",
      "epoch 50, train_loss 0.000799, test_loss 0.000328\n",
      "TorchNeuron(\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=500, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "epoch 1, train_loss 0.015686, test_loss 0.013513\n",
      "epoch 2, train_loss 0.014256, test_loss 0.011700\n",
      "epoch 3, train_loss 0.012376, test_loss 0.009659\n",
      "epoch 4, train_loss 0.009897, test_loss 0.007081\n",
      "epoch 5, train_loss 0.007182, test_loss 0.004619\n",
      "epoch 6, train_loss 0.005007, test_loss 0.003015\n",
      "epoch 7, train_loss 0.003800, test_loss 0.001997\n",
      "epoch 8, train_loss 0.003060, test_loss 0.001524\n",
      "epoch 9, train_loss 0.002713, test_loss 0.001228\n",
      "epoch 10, train_loss 0.002400, test_loss 0.001076\n",
      "epoch 11, train_loss 0.002266, test_loss 0.000959\n",
      "epoch 12, train_loss 0.002030, test_loss 0.000876\n",
      "epoch 13, train_loss 0.001978, test_loss 0.000807\n",
      "epoch 14, train_loss 0.001852, test_loss 0.000764\n",
      "epoch 15, train_loss 0.001822, test_loss 0.000718\n",
      "epoch 16, train_loss 0.001723, test_loss 0.000701\n",
      "epoch 17, train_loss 0.001651, test_loss 0.000635\n",
      "epoch 18, train_loss 0.001568, test_loss 0.000627\n",
      "epoch 19, train_loss 0.001511, test_loss 0.000589\n",
      "epoch 20, train_loss 0.001511, test_loss 0.000557\n",
      "epoch 21, train_loss 0.001420, test_loss 0.000542\n",
      "epoch 22, train_loss 0.001334, test_loss 0.000528\n",
      "epoch 23, train_loss 0.001336, test_loss 0.000515\n",
      "epoch 24, train_loss 0.001319, test_loss 0.000490\n",
      "epoch 25, train_loss 0.001262, test_loss 0.000480\n",
      "epoch 26, train_loss 0.001244, test_loss 0.000457\n",
      "epoch 27, train_loss 0.001210, test_loss 0.000448\n",
      "epoch 28, train_loss 0.001147, test_loss 0.000438\n",
      "epoch 29, train_loss 0.001146, test_loss 0.000404\n",
      "epoch 30, train_loss 0.001123, test_loss 0.000411\n",
      "epoch 31, train_loss 0.001113, test_loss 0.000392\n",
      "epoch 32, train_loss 0.001078, test_loss 0.000382\n",
      "epoch 33, train_loss 0.001039, test_loss 0.000359\n",
      "epoch 34, train_loss 0.001049, test_loss 0.000358\n",
      "epoch 35, train_loss 0.001047, test_loss 0.000346\n",
      "epoch 36, train_loss 0.000982, test_loss 0.000346\n",
      "epoch 37, train_loss 0.000990, test_loss 0.000329\n",
      "epoch 38, train_loss 0.000980, test_loss 0.000330\n",
      "epoch 39, train_loss 0.000944, test_loss 0.000323\n",
      "epoch 40, train_loss 0.000935, test_loss 0.000312\n",
      "epoch 41, train_loss 0.000912, test_loss 0.000305\n",
      "epoch 42, train_loss 0.000889, test_loss 0.000298\n",
      "epoch 43, train_loss 0.000886, test_loss 0.000305\n",
      "epoch 44, train_loss 0.000870, test_loss 0.000288\n",
      "epoch 45, train_loss 0.000859, test_loss 0.000287\n",
      "epoch 46, train_loss 0.000831, test_loss 0.000283\n",
      "epoch 47, train_loss 0.000821, test_loss 0.000281\n",
      "epoch 48, train_loss 0.000817, test_loss 0.000268\n",
      "epoch 49, train_loss 0.000829, test_loss 0.000262\n",
      "epoch 50, train_loss 0.000788, test_loss 0.000259\n",
      "TorchNeuron(\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=500, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "epoch 1, train_loss 0.015502, test_loss 0.015094\n",
      "epoch 2, train_loss 0.013948, test_loss 0.013659\n",
      "epoch 3, train_loss 0.012277, test_loss 0.011516\n",
      "epoch 4, train_loss 0.010059, test_loss 0.008679\n",
      "epoch 5, train_loss 0.007372, test_loss 0.005914\n",
      "epoch 6, train_loss 0.005259, test_loss 0.003945\n",
      "epoch 7, train_loss 0.003919, test_loss 0.002652\n",
      "epoch 8, train_loss 0.003192, test_loss 0.002105\n",
      "epoch 9, train_loss 0.002709, test_loss 0.001602\n",
      "epoch 10, train_loss 0.002527, test_loss 0.001406\n",
      "epoch 11, train_loss 0.002376, test_loss 0.001202\n",
      "epoch 12, train_loss 0.002106, test_loss 0.001100\n",
      "epoch 13, train_loss 0.002024, test_loss 0.001020\n",
      "epoch 14, train_loss 0.001873, test_loss 0.000952\n",
      "epoch 15, train_loss 0.001792, test_loss 0.000916\n",
      "epoch 16, train_loss 0.001713, test_loss 0.000860\n",
      "epoch 17, train_loss 0.001631, test_loss 0.000836\n",
      "epoch 18, train_loss 0.001625, test_loss 0.000779\n",
      "epoch 19, train_loss 0.001510, test_loss 0.000746\n",
      "epoch 20, train_loss 0.001452, test_loss 0.000751\n",
      "epoch 21, train_loss 0.001471, test_loss 0.000692\n",
      "epoch 22, train_loss 0.001414, test_loss 0.000669\n",
      "epoch 23, train_loss 0.001376, test_loss 0.000639\n",
      "epoch 24, train_loss 0.001337, test_loss 0.000622\n",
      "epoch 25, train_loss 0.001303, test_loss 0.000603\n",
      "epoch 26, train_loss 0.001248, test_loss 0.000575\n",
      "epoch 27, train_loss 0.001242, test_loss 0.000575\n",
      "epoch 28, train_loss 0.001175, test_loss 0.000552\n",
      "epoch 29, train_loss 0.001154, test_loss 0.000522\n",
      "epoch 30, train_loss 0.001148, test_loss 0.000517\n",
      "epoch 31, train_loss 0.001118, test_loss 0.000494\n",
      "epoch 32, train_loss 0.001107, test_loss 0.000483\n",
      "epoch 33, train_loss 0.001080, test_loss 0.000482\n",
      "epoch 34, train_loss 0.001039, test_loss 0.000476\n",
      "epoch 35, train_loss 0.001015, test_loss 0.000447\n",
      "epoch 36, train_loss 0.001018, test_loss 0.000441\n",
      "epoch 37, train_loss 0.000965, test_loss 0.000426\n",
      "epoch 38, train_loss 0.000949, test_loss 0.000422\n",
      "epoch 39, train_loss 0.000942, test_loss 0.000395\n",
      "epoch 40, train_loss 0.000952, test_loss 0.000387\n",
      "epoch 41, train_loss 0.000943, test_loss 0.000386\n",
      "epoch 42, train_loss 0.000921, test_loss 0.000375\n",
      "epoch 43, train_loss 0.000873, test_loss 0.000390\n",
      "epoch 44, train_loss 0.000912, test_loss 0.000363\n",
      "epoch 45, train_loss 0.000868, test_loss 0.000373\n",
      "epoch 46, train_loss 0.000849, test_loss 0.000365\n",
      "epoch 47, train_loss 0.000835, test_loss 0.000347\n",
      "epoch 48, train_loss 0.000829, test_loss 0.000375\n",
      "epoch 49, train_loss 0.000818, test_loss 0.000342\n",
      "epoch 50, train_loss 0.000820, test_loss 0.000341\n",
      "TorchNeuron(\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=500, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "epoch 1, train_loss 0.015277, test_loss 0.015144\n",
      "epoch 2, train_loss 0.013697, test_loss 0.013532\n",
      "epoch 3, train_loss 0.011988, test_loss 0.011102\n",
      "epoch 4, train_loss 0.009458, test_loss 0.008177\n",
      "epoch 5, train_loss 0.006801, test_loss 0.005428\n",
      "epoch 6, train_loss 0.004945, test_loss 0.003433\n",
      "epoch 7, train_loss 0.003714, test_loss 0.002372\n",
      "epoch 8, train_loss 0.003088, test_loss 0.001778\n",
      "epoch 9, train_loss 0.002652, test_loss 0.001477\n",
      "epoch 10, train_loss 0.002421, test_loss 0.001258\n",
      "epoch 11, train_loss 0.002289, test_loss 0.001136\n",
      "epoch 12, train_loss 0.002071, test_loss 0.001019\n",
      "epoch 13, train_loss 0.001952, test_loss 0.000955\n",
      "epoch 14, train_loss 0.001927, test_loss 0.000954\n",
      "epoch 15, train_loss 0.001746, test_loss 0.000967\n",
      "epoch 16, train_loss 0.001700, test_loss 0.000778\n",
      "epoch 17, train_loss 0.001675, test_loss 0.000738\n",
      "epoch 18, train_loss 0.001612, test_loss 0.000706\n",
      "epoch 19, train_loss 0.001515, test_loss 0.000695\n",
      "epoch 20, train_loss 0.001492, test_loss 0.000646\n",
      "epoch 21, train_loss 0.001444, test_loss 0.000633\n",
      "epoch 22, train_loss 0.001358, test_loss 0.000609\n",
      "epoch 23, train_loss 0.001300, test_loss 0.000587\n",
      "epoch 24, train_loss 0.001285, test_loss 0.000589\n",
      "epoch 25, train_loss 0.001265, test_loss 0.000578\n",
      "epoch 26, train_loss 0.001216, test_loss 0.000557\n",
      "epoch 27, train_loss 0.001217, test_loss 0.000531\n",
      "epoch 28, train_loss 0.001135, test_loss 0.000491\n",
      "epoch 29, train_loss 0.001153, test_loss 0.000510\n",
      "epoch 30, train_loss 0.001118, test_loss 0.000479\n",
      "epoch 31, train_loss 0.001053, test_loss 0.000470\n",
      "epoch 32, train_loss 0.001080, test_loss 0.000457\n",
      "epoch 33, train_loss 0.001070, test_loss 0.000448\n",
      "epoch 34, train_loss 0.001040, test_loss 0.000445\n",
      "epoch 35, train_loss 0.001001, test_loss 0.000430\n",
      "epoch 36, train_loss 0.000999, test_loss 0.000442\n",
      "epoch 37, train_loss 0.000987, test_loss 0.000439\n",
      "epoch 38, train_loss 0.000958, test_loss 0.000400\n",
      "epoch 39, train_loss 0.000910, test_loss 0.000398\n",
      "epoch 40, train_loss 0.000923, test_loss 0.000399\n",
      "epoch 41, train_loss 0.000920, test_loss 0.000382\n",
      "epoch 42, train_loss 0.000897, test_loss 0.000378\n",
      "epoch 43, train_loss 0.000865, test_loss 0.000376\n",
      "epoch 44, train_loss 0.000872, test_loss 0.000359\n",
      "epoch 45, train_loss 0.000855, test_loss 0.000346\n",
      "epoch 46, train_loss 0.000858, test_loss 0.000338\n",
      "epoch 47, train_loss 0.000847, test_loss 0.000323\n",
      "epoch 48, train_loss 0.000839, test_loss 0.000324\n",
      "epoch 49, train_loss 0.000800, test_loss 0.000334\n",
      "epoch 50, train_loss 0.000800, test_loss 0.000324\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "def train(train_data_loader, test_data_loader):\n",
    "\n",
    "    net = TorchNeuron(input_size, hidden_size, output_size, drop_out_rate=0.3)\n",
    "    print(net)\n",
    "    loss_func = nn.MSELoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, weight_decay=0.0)\n",
    "\n",
    "    train_loss_list = []\n",
    "    test_loss_list = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train_epoch(data_loader=train_data_loader, net=net,\n",
    "                                            loss_func=loss_func, optimizer=optimizer, device=device)\n",
    "        test_loss = test_epoch(data_loader=test_data_loader, net=net,\n",
    "                                         loss_func=loss_func, device=device)\n",
    "\n",
    "        print('epoch %d, train_loss %f, test_loss %f'\n",
    "              % (epoch+1, train_loss, test_loss))\n",
    "\n",
    "        train_loss_list.append(train_loss)\n",
    "        test_loss_list.append(test_loss)\n",
    "\n",
    "    return train_loss_list, test_loss_list\n",
    "\n",
    "# 参数配置\n",
    "device = 'cpu'\n",
    "input_size = x_train.shape[1]\n",
    "hidden_size = 128\n",
    "output_size = 1\n",
    "\n",
    "batch_size = 256\n",
    "num_epochs = 50\n",
    "lr = 0.1\n",
    "\n",
    "X = torch.cat((x_train, x_test))\n",
    "y = torch.cat((y_train, y_test))\n",
    "\n",
    "indices = np.arange(0, X.shape[0])\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "kf_train_loss, kf_test_loss = [], []\n",
    "for train_index, test_index in kf.split(indices):\n",
    "    train_index = torch.LongTensor(train_index)\n",
    "    test_index = torch.LongTensor(test_index)\n",
    "\n",
    "    train_x = torch.index_select(X, dim=0, index=train_index)\n",
    "    train_y = torch.index_select(y, dim=0, index=train_index)\n",
    "    test_x = torch.index_select(X, dim=0, index=test_index)\n",
    "    test_y = torch.index_select(y, dim=0, index=test_index)\n",
    "\n",
    "    train_set = Data.TensorDataset(train_x, train_y)\n",
    "    test_set = Data.TensorDataset(test_x, test_y)\n",
    "\n",
    "    train_data_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    test_data_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # 训练\n",
    "    train_loss_list, test_loss_list = train(train_data_loader, test_data_loader)\n",
    "    kf_train_loss.append(train_loss_list)\n",
    "    kf_test_loss.append(test_loss_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00028868 0.00031434 0.00031275 0.00030661 0.0003032  0.0003139\n",
      " 0.0003213  0.00025909 0.00034103 0.00032338]\n",
      "[0.00163858 0.00184026 0.00177395 0.00171711 0.00174201 0.00167926\n",
      " 0.00180045 0.00147343 0.00179616 0.00171343]\n"
     ]
    }
   ],
   "source": [
    "kf_train_loss_np = np.array(kf_train_loss)\n",
    "kf_test_loss_np = np.array(kf_test_loss)\n",
    "\n",
    "print(kf_test_loss_np.min(axis=1))\n",
    "print(kf_test_loss_np.mean(axis=1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}