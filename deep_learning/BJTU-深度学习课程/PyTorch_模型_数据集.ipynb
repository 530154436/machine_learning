{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "significant-coaching",
   "metadata": {},
   "source": [
    "### PyTorch安装与环境配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "immune-column",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.utils.data as Data\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "violent-level",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2024, 0.8727, 0.1505],\n",
       "        [0.4524, 0.6841, 0.6142]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-novelty",
   "metadata": {},
   "source": [
    "### 基本数据处理与计算操作\n",
    "#### 创建Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ruled-offset",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1210e-44, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个2x3的未初始化的Tensor\n",
    "torch.empty(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beneficial-prime",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0325, 0.8458, 0.9704],\n",
       "        [0.9990, 0.0427, 0.1527]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个2x3的随机初始化的Tensor\n",
    "torch.rand(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "corporate-vietnamese",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个2x3的long型全0的Tensor\n",
    "torch.zeros(2, 3, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "extensive-authorization",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 5, 3],\n",
       "        [2, 2, 5]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 直接根据数据创建\n",
    "x = torch.tensor([[5,5,3], [2,2,5]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "moderate-humanitarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 返回的tensor默认具有相同的torch.dtype和torch.device \n",
    "x = x.new_ones(2, 3, dtype=torch.float64)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "outdoor-deployment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6176, -0.8275, -1.7215],\n",
       "        [ 0.9033, -0.1312, -2.8815]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指定新的数据类型\n",
    "x = torch.randn_like(x, dtype=torch.float)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "meaning-reserve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "incomplete-action",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-silver",
   "metadata": {},
   "source": [
    "#### Tensor的相关操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrong-college",
   "metadata": {},
   "source": [
    "##### 算术操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "occupied-stretch",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4473, 0.3372, 0.4641],\n",
       "         [0.9403, 0.1416, 0.7600]]),\n",
       " tensor([[0.3539, 0.0769, 0.2622],\n",
       "         [0.6555, 0.6301, 0.6811]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2, 3) \n",
    "y = torch.rand(2, 3)\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "tutorial-clone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8012, 0.4141, 0.7263],\n",
       "        [1.5958, 0.7716, 1.4411]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加法形式1\n",
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "informational-hotel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8012, 0.4141, 0.7263],\n",
       "        [1.5958, 0.7716, 1.4411]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加法形式2\n",
    "torch.add(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "democratic-morocco",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8012, 0.4141, 0.7263],\n",
       "        [1.5958, 0.7716, 1.4411]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加法形式3，inplace(原地操作)\n",
    "y.add_(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "artistic-gentleman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.8012, 1.5958],\n",
       "         [0.4141, 0.7716],\n",
       "         [0.7263, 1.4411]]),\n",
       " tensor([[0.8012, 1.5958],\n",
       "         [0.4141, 0.7716],\n",
       "         [0.7263, 1.4411]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.copy_(y), x.t_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-distribution",
   "metadata": {},
   "source": [
    "##### 索引\n",
    "索引出来的结果与原数据`共享内存`，也即修改一个，另一个会跟着修改。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "honest-check",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.8012, 1.5958],\n",
       "         [0.4141, 0.7716],\n",
       "         [0.7263, 1.4411]]),\n",
       " tensor([[0.8012, 0.4141, 0.7263],\n",
       "         [1.5958, 0.7716, 1.4411]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "recovered-tragedy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8012, 1.5958])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x[0, :]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "patient-uruguay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.8012, 2.5958])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y += 1\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "champion-rachel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.8012, 2.5958])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identified-boards",
   "metadata": {},
   "source": [
    "##### 切片 index_select\n",
    "沿着指定维度对输入进行切片，取index中指定的相应项(index 为一个 LongTensor)，然后返回到一个新的张量， 返回的张量与原始张量 Tensor 有相同的维度(在指定轴上)。\n",
    "\n",
    "注意： `返回的张量不与原始张量共享内存空间`。<br>\n",
    "\n",
    "参数:<br>\n",
    "input (Tensor)         – 输入张量<br>\n",
    "dim (int)              – 索引的轴<br>\n",
    "index (LongTensor)     – 包含索引下标的一维张量<br>\n",
    "out (Tensor, optional) – 目标张量<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bearing-condition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3500,  1.6039,  0.5196,  0.2308],\n",
       "        [ 0.5187,  0.1429, -0.7139,  1.2255],\n",
       "        [-0.0683,  0.7346, -0.3223, -1.0955]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "sorted-statistics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = torch.LongTensor([0, 2])\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "italian-routine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3500,  1.6039,  0.5196,  0.2308],\n",
       "        [-0.0683,  0.7346, -0.3223, -1.0955]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 按行(dim=0)选取第0行、第2行\n",
    "torch.index_select(x, 0, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-calendar",
   "metadata": {},
   "source": [
    "##### 改变形状 view/reshape\n",
    "1. `view()`<br>\n",
    "注意view()**返回的新Tensor与源Tensor虽然可能有不同的size**，但`共享data`。<br>\n",
    "即更改其中的一个，另外一个也会跟着改变。(顾名思义，view仅仅是改变了对这个张量的 观察角度，内部数据并未改变)\n",
    "2. `reshape()` 和 `clone()`<br> \n",
    "Pytorch还提供了一个 reshape() 方法可以改变形状，但是此函数并不能保证返回的是其拷贝，所以不推荐使用。<br> \n",
    "我们推荐先用 clone() 创造一个副本然后再使用view()。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "injured-metabolism",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.8012, 2.5958],\n",
       "         [0.4141, 0.7716],\n",
       "         [0.7263, 1.4411]]),\n",
       " tensor([1.8012, 2.5958]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "czech-monte",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.8012, 2.5958, 0.4141, 0.7716, 0.7263, 1.4411])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一个tensor必须是连续的contiguous()才能被查看。\n",
    "# 一开始不加contiguous()，报 “view size is not compatible ... ” 错误，因为在 2.2.1 索引时修改了 x 数组的值\n",
    "y = x.contiguous().view(6)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "manual-lingerie",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8012, 2.5958, 0.4141],\n",
       "        [0.7716, 0.7263, 1.4411]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x.contiguous().view(-1, 3) # -1所指的维度可以根据其他维度的值推出来\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "outdoor-inclusion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([6]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size(), y.size(), z.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "reflected-sheep",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.8012, 2.5958, 0.4141, 0.7716, 0.7263, 1.4411]),\n",
       " tensor([[ 0.8012,  1.5958],\n",
       "         [-0.5859, -0.2284],\n",
       "         [-0.2737,  0.4411]]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cp = x.clone().contiguous().view(6)\n",
    "x -= 1\n",
    "x_cp, x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-geneva",
   "metadata": {},
   "source": [
    "#### 广播机制\n",
    "当我们对两个形状不同的Tensor按元素运算时，可能会触发`广播(broadcasting)机制`。 <br>\n",
    "先适当复制元素使这两个Tensor形状相同后再按元素运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ordered-homeless",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2]]),\n",
       " tensor([[1],\n",
       "         [2],\n",
       "         [3]]),\n",
       " tensor([[2, 3],\n",
       "         [3, 4],\n",
       "         [4, 5]]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x 中第一行的2个 元素被广播(复制)到了第二行和第三行\n",
    "# y 中第一列的3个元素被广播(复制)到 了第二列\n",
    "x = torch.arange(1, 3).view(1, 2)\n",
    "y = torch.arange(1, 4).view(3, 1)\n",
    "x, y, x+y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-anniversary",
   "metadata": {},
   "source": [
    "#### Tensor和NumPy相互转换\n",
    "+ `numpy()`和`from_numpy()` <br>\n",
    "这两个函数所产生的的Tensor和NumPy中的数组共享相同的内存(所以他们之间的转换很快)，改变其中一个时另一个也会改变!\n",
    "+ `torch.tensor()` <br>\n",
    "进行**数据拷贝**，所以返回的Tensor和原来 的数据不再共享内存。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-parameter",
   "metadata": {},
   "source": [
    "##### Tensor转NumPy数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dramatic-notebook",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1.]), array([1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3)\n",
    "b = a.numpy()\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bearing-mining",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2.]), array([2., 2., 2.], dtype=float32))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a += 1\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "grave-chassis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 3., 3.]), array([3., 3., 3.], dtype=float32))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b += 1\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-regard",
   "metadata": {},
   "source": [
    "##### NumPy数组转 Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "automatic-click",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 1., 1.]), tensor([1., 1., 1.], dtype=torch.float64))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones(3)\n",
    "b = torch.from_numpy(a)\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "nominated-expense",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 2., 2.]), tensor([2., 2., 2.], dtype=torch.float64))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a += 1\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "determined-shelter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3., 3., 3.]), tensor([3., 3., 3.], dtype=torch.float64))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b += 1\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aging-panel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4., 4., 4.]), tensor([3., 3., 3.], dtype=torch.float64))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用torch.tensor()将NumPy数组转换成Tensor(不再共享内存)\n",
    "c = torch.tensor(a)\n",
    "a += 1\n",
    "a, c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-xerox",
   "metadata": {},
   "source": [
    "#### Tensor on GPU\n",
    "+ `to()`<br>\n",
    "将Tensor在CPU和GPU(需要硬件支持)之间相互移动。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-raise",
   "metadata": {},
   "source": [
    "#### 自动求梯度\n",
    "+ `autograd 包`<br>\n",
    "根据输入和**前向传播**过程自动构建计算图，并执行**反向传播**。\n",
    "+ `Tensor`是autograd包的核心类<br>\n",
    "将其属性`.requires_grad`设置为True，它将开始追踪在其上的所有操作(这样就可以利用链式法则进行梯度传播了)。<br>\n",
    "完成计算后，可以调用`.backward()`来完成所有梯度计算。此Tensor的梯度将累积到.grad属性中。<br>\n",
    "如果不想要被继续追踪，可以调用`.detach()`将其从追踪记录中分离出来，这样就可以防止将来的计算被追踪，这样梯度就传不过去了。<br>\n",
    "此外，还可以用`with torch.no_grad()`将不想被追踪的操作代码块包裹起来，这种方法在评估模型的时候很常用，因为在评估模型时，我们并不需要计算 可训练参数(requires_grad=True)的梯度。\n",
    "+ `Function`是另外一个很重要的类。<br>\n",
    "Tensor和Function互相结合就可以构建一个记录有整个计算过程的**有向无环图(DAG)**。<br>\n",
    "每个Tensor都有一个.grad_fn属性，该属性即创建该Tensor的Function, 就是说该Tensor是不是通过某些运算得到的，若是，则grad_fn返回一个与这些运算相关的对象，否则是None。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-parts",
   "metadata": {},
   "source": [
    "##### Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ambient-facing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1.],\n",
       "         [1., 1.]], requires_grad=True),\n",
       " None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个Tensor并设置requires_grad=True:\n",
    "# x是直接创建的，所以它没有grad_fn\n",
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "x, x.grad_fn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "pleasant-appreciation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3., 3.],\n",
       "         [3., 3.]], grad_fn=<AddBackward0>),\n",
       " <AddBackward0 at 0x133ddf400>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y 是通过一个加法操作创建的，所以它有一个为<AddBackward>的grad_fn\n",
    "y = x + 2\n",
    "y, y.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "respiratory-starter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[27., 27.],\n",
       "         [27., 27.]], grad_fn=<MulBackward0>),\n",
       " tensor(27., grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = y * y * 3 \n",
    "out = z.mean()\n",
    "z, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "confirmed-karaoke",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过.requires_grad_()来用in-place的方式改变requires_grad属性\n",
    "a = torch.randn(2, 2)\n",
    "a = ((a * 3) / (a - 1))\n",
    "a.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "present-payment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.requires_grad_(True)\n",
    "a.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "tropical-throw",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SumBackward0 at 0x133ddf550>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = (a * a).sum()\n",
    "b.grad_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-denver",
   "metadata": {},
   "source": [
    "##### 梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "protecting-split",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.5000, 4.5000],\n",
       "        [4.5000, 4.5000]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "y = x + 2\n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "out.backward()  # 等价于 out.backward(torch.tensor(1.))\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-justice",
   "metadata": {},
   "source": [
    "令out为o，因为\n",
    "$$\n",
    "O = \\frac 1 4 \\sum_i^4 z_i = \\frac 1 4 \\sum_i^4 3y_i^2 = \\frac 1 4 \\sum_i^4 3(x_i+2)^2\n",
    "$$\n",
    "所以<br>\n",
    "$$\n",
    "\\frac{\\partial{O}}{\\partial{x_i}}|_{x_i=1} = \\frac 9 2 = 4.5\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "rental-isaac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.5000, 5.5000],\n",
       "        [5.5000, 5.5000]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 注意grad是累加的\n",
    "out2 = x.sum()\n",
    "out2.backward()      # 梯度未清零，累加梯度\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "junior-atlas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out3 = x.sum()\n",
    "x.grad.data.zero_()\n",
    "out3.backward()      # 梯度清零后，x的梯度为1\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-albert",
   "metadata": {},
   "source": [
    "##### 反向传播\n",
    "`y.backward()`<br>\n",
    "+ 如果 $y$ 是**标量**，则不需要为backward()传入任何参数。<br>\n",
    "+ 如果 $y$ 是**向量**，需要传入一个与y同形的Tensor。<br>\n",
    "这样为了避免向量(甚至更高维张量) 对张量求导，因此转换成标量对张量进行求导。<br>\n",
    "`不允许张量对张量求导`，只允许标量对张量求导，求导结果是和自变量同形的张量。<br>\n",
    "必要时我们要把张量通过将所有张量的元素`加权求和`的方式转换为标量。<br>\n",
    "\n",
    "假设 $𝒚$ 由自变量 $𝒙$ 计算而来，$𝒘$ 是和 $𝒚$ 同形的张量则 $𝐲. 𝐛𝐚𝐜𝐤𝐰𝐚𝐫𝐝(𝒘)$ 的含义是: <br>\n",
    "先计算 $𝒍$ = 𝐭𝐨𝐫𝐜𝐡.𝐬𝐮𝐦($𝒚$ ∗ $𝒘$)，因此 𝒍 是一个标量，然后我们再求 𝒍 对自变量 𝒙 的导数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "flexible-integer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4.], requires_grad=True),\n",
       " tensor([2., 4., 6., 8.], grad_fn=<MulBackward0>),\n",
       " tensor([[2., 4.],\n",
       "         [6., 8.]], grad_fn=<ViewBackward>))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0, 4.0], requires_grad=True)\n",
    "y = 2 * x\n",
    "z = y.view(2, 2)\n",
    "x, y, z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-there",
   "metadata": {},
   "source": [
    "此时 𝒛 不是一个标量，所以在调用backward()时需要传入一个和 𝒛 同形的权重向量进行加权求和来得到一个标量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "likely-sequence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0000, 0.2000, 0.0200, 0.0020])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = torch.tensor([[1.0, 0.1], [0.01, 0.001]], dtype=torch.float) \n",
    "z.backward(v)\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-palmer",
   "metadata": {},
   "source": [
    "### 线性回归实现\n",
    "线性回归(Linear Regression)是机器学习和统计学中最基础和广泛应用的模型，是一种对自变量和因变量之间关系进行建模的回归分析。\n",
    "从机器学习的角度来看，自变量就是样本的特征向量 $x \\in R$ (每一维对应一个自变量)，因变量是标签 $y$，这里 $x \\in R$ 是连续值。假设空间是一组参数化的线性函数\n",
    "$$\n",
    "f(x;𝑤,𝑏) = 𝑥w^T+𝑏\n",
    "$$\n",
    "其中，权重向量 $𝒘$ 和偏置 $𝒃$ 是线性回归需要学习的参数， 函数 $f(x;𝑤,𝑏)$ 称为线性模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-bearing",
   "metadata": {},
   "source": [
    "#### 手动实现线性回归\n",
    "##### 生成数据\n",
    "设训练数据集样本数为1000，输入个数(特征数)为2，给定随机生成的批量样本特征 $X \\in R^{1000 \\times 2}$。 <br>\n",
    "线性回归模型的真实权重 $ w = [2 , −3.4]^T $ 和偏差 $𝑏 = 4.2$, 以及一个随机噪声项 $\\epsilon$ 来生成标签。\n",
    "$$𝑦 = 𝑥𝑤^T + 𝑏 + \\epsilon$$\n",
    "其中，噪声项 $\\epsilon$ 服从均值0、标准差为0.01的`正态分布`。噪声代表了数据中无意义的干扰。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "multiple-detroit",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.0405,  0.0453],\n",
       "         [ 2.5889,  0.7232],\n",
       "         [ 0.5254, -0.2441],\n",
       "         ...,\n",
       "         [ 0.5982, -2.0866],\n",
       "         [-0.3629, -0.3041],\n",
       "         [ 0.6341,  0.4805]]),\n",
       " tensor([ 1.9673e+00,  6.9045e+00,  6.0855e+00,  5.8264e+00, -3.8851e+00,\n",
       "          7.3529e+00,  2.4600e+00,  4.3753e+00,  1.3303e+00,  7.1018e+00,\n",
       "          3.1593e+00,  1.0315e+00,  4.7337e+00,  4.0286e+00,  7.8975e+00,\n",
       "          1.7722e+00,  8.2931e+00,  6.9915e+00,  1.5817e+00,  3.7926e+00,\n",
       "         -2.4969e-01,  5.1320e+00,  3.7706e+00, -3.2242e+00,  3.0918e+00,\n",
       "          3.2025e+00,  7.9565e+00, -7.9678e-01,  2.5207e+00,  7.6772e+00,\n",
       "          6.2772e+00,  4.9812e+00,  4.1395e+00, -1.4928e+00,  3.9516e+00,\n",
       "         -3.6948e-01, -6.5166e-02,  7.5782e+00, -2.2773e+00,  8.3967e+00,\n",
       "          5.7408e+00, -7.2339e+00,  2.2819e+00,  1.3723e+01,  1.4181e+00,\n",
       "          2.9324e+00,  1.1568e+01,  7.6827e+00,  5.5807e-01, -9.8122e-02,\n",
       "          1.3212e+01,  7.5512e+00,  2.9453e+00,  8.6877e+00,  1.4549e+00,\n",
       "          1.2148e+01,  2.4021e+00,  2.5624e+00,  7.6634e+00,  1.8531e+00,\n",
       "          4.3967e+00,  2.2740e+00, -1.2870e+00,  1.1591e+01,  1.1037e+01,\n",
       "          1.9570e+00, -3.2349e-01,  1.1021e+00,  7.8326e+00,  6.7315e+00,\n",
       "          6.3626e+00,  1.3480e+00,  1.0113e+01,  5.1830e+00,  5.1400e+00,\n",
       "          2.2506e+00,  4.7448e+00,  7.5961e+00, -1.2580e+00, -1.2850e+00,\n",
       "          8.6735e+00, -1.2104e-01,  7.9620e+00,  1.2567e+01,  3.0670e+00,\n",
       "         -1.7717e-01, -7.0065e+00,  3.0400e+00,  1.8755e+00,  6.5012e+00,\n",
       "          8.5681e-01,  9.2253e-01, -1.0055e+00,  5.5748e+00,  1.2340e+00,\n",
       "          5.3972e+00,  4.6790e+00,  5.3646e+00,  2.6304e+00,  1.6212e+00,\n",
       "          6.3525e+00,  4.3166e+00,  7.4197e+00,  5.6268e+00,  2.5885e+00,\n",
       "          8.1157e+00,  4.4971e+00,  2.6807e-01,  3.2225e+00,  8.1019e+00,\n",
       "          3.1783e-01,  3.2686e+00,  8.5367e+00,  3.9559e+00,  5.1248e+00,\n",
       "          1.2080e+01,  9.3898e+00,  6.0515e+00,  4.2063e+00,  6.0624e+00,\n",
       "          6.7224e+00,  1.0940e+01,  1.0188e+01, -3.0240e+00,  1.2020e+01,\n",
       "         -3.6207e+00,  6.8863e+00,  7.6896e+00,  1.8339e+00,  1.0396e+01,\n",
       "         -8.1638e-01,  7.5648e+00,  2.0005e+00,  6.0067e+00,  4.3852e+00,\n",
       "          4.9303e+00,  8.0404e+00,  2.6085e+00,  5.5861e+00,  6.4386e+00,\n",
       "          5.1093e+00, -1.0114e+00,  7.9111e+00,  3.0373e+00,  6.5994e+00,\n",
       "          3.3417e+00,  2.1923e+00,  8.1042e+00, -2.4565e+00,  4.5021e+00,\n",
       "          2.4824e+00,  2.9777e+00,  8.3259e+00,  7.7662e+00,  3.8243e+00,\n",
       "          9.7899e+00,  2.7391e+00,  2.4037e+00,  2.2906e+00,  1.3696e+00,\n",
       "          6.2492e+00,  4.7777e+00,  7.4612e+00,  5.9304e+00,  1.7452e+00,\n",
       "         -5.0079e+00,  1.5945e+00,  1.2498e+01,  3.3472e+00,  4.2501e+00,\n",
       "          5.7413e+00,  6.7079e-01,  4.3731e+00,  2.7708e+00, -1.3024e-01,\n",
       "          5.4000e-01, -5.7237e-03, -2.6321e+00,  9.0146e+00,  7.0214e+00,\n",
       "          2.4523e+00,  1.2257e+00, -6.2669e-01,  1.1543e+01,  5.5822e+00,\n",
       "          1.0434e+01,  6.0461e+00,  2.3498e+00,  8.8077e+00,  7.2213e+00,\n",
       "          2.8966e+00,  5.4899e+00,  7.6678e+00,  3.8286e+00, -1.2807e+00,\n",
       "         -4.1268e+00,  3.2218e+00,  2.6032e+00,  5.9825e+00, -1.4689e+00,\n",
       "          8.6950e-01, -2.1641e+00,  6.1681e+00, -4.6810e+00, -1.5180e+00,\n",
       "          6.2683e+00,  3.8035e+00,  1.3270e+01, -4.9107e-01,  3.9563e+00,\n",
       "         -1.1668e+00,  3.6504e+00,  3.6419e+00,  7.8866e+00,  3.6201e+00,\n",
       "          1.2543e+01,  5.6437e+00,  3.3027e+00,  4.4849e+00,  7.4593e+00,\n",
       "          3.9966e+00, -9.1572e-01, -2.3875e+00, -2.2580e+00,  4.1684e+00,\n",
       "         -1.2260e-01, -4.1659e-01, -4.6662e-02,  8.2758e+00,  1.1839e+01,\n",
       "          1.9827e+00, -1.0947e+00,  4.1616e+00,  1.1559e+01,  6.2361e-01,\n",
       "         -9.1629e-01,  6.0349e+00, -1.7071e+00,  3.2528e+00,  2.0058e+00,\n",
       "          1.8967e+00,  3.2735e+00,  1.5234e+01, -2.4695e-01,  6.8972e+00,\n",
       "          1.4534e+00,  3.5451e+00,  1.0890e+00,  3.1421e+00,  2.0840e+00,\n",
       "          5.5021e-01,  1.5753e+00,  5.5967e+00,  8.7894e+00,  2.1528e+00,\n",
       "         -2.3470e+00,  4.4969e+00, -2.8374e+00, -2.3879e+00,  1.1409e+01,\n",
       "          4.7200e+00,  5.9068e+00,  9.8069e+00,  4.9063e+00,  1.9884e+00,\n",
       "          2.9533e+00,  3.2121e+00,  1.9572e+00,  8.1848e+00,  8.7494e+00,\n",
       "          7.6779e+00,  7.1427e+00,  9.8269e+00,  9.1718e+00,  1.4710e+00,\n",
       "         -1.1973e+00, -1.7261e+00, -4.6891e+00,  4.2595e+00,  1.0297e+01,\n",
       "         -2.2350e+00,  5.1896e+00,  2.5195e+00,  2.1960e+00, -3.3593e-03,\n",
       "          9.8911e+00,  1.0328e+01,  8.4855e+00,  7.2903e+00,  5.8580e+00,\n",
       "         -5.8850e-01,  5.6624e+00,  8.8364e-01,  2.9414e+00,  1.1301e+00,\n",
       "          7.1516e+00,  1.4107e+00,  4.9128e+00,  2.3838e+00,  2.3711e+00,\n",
       "          4.2579e+00,  7.1862e+00,  1.0022e+01,  6.2900e+00,  5.9779e+00,\n",
       "          7.6714e+00,  1.0533e+01,  1.5431e+00,  7.5574e+00,  9.1702e-01,\n",
       "          1.2930e+01,  4.5921e+00,  2.7451e+00,  1.7082e+00,  8.4907e+00,\n",
       "          2.9904e+00, -1.9039e+00,  1.6587e+00,  3.8708e+00,  6.3967e+00,\n",
       "          6.6524e+00,  7.2317e+00,  3.7117e+00,  5.6872e+00, -5.4238e-01,\n",
       "          6.2972e+00,  2.7405e+00,  4.7559e+00,  5.5817e+00,  6.6774e+00,\n",
       "          4.2208e+00,  2.4548e+00,  6.1506e+00,  4.6371e+00,  3.5716e+00,\n",
       "         -1.4125e+00, -2.3738e+00,  6.2172e+00,  4.0594e+00,  8.7524e+00,\n",
       "         -8.7981e-01,  1.1007e+01,  5.6714e+00, -4.7495e-01,  3.7667e+00,\n",
       "          5.9763e+00,  1.9620e+00,  2.7049e+00,  1.1926e+01, -9.6298e-01,\n",
       "          3.0143e+00, -2.4262e+00,  8.6482e-01,  6.2328e+00, -8.4805e-01,\n",
       "          7.3872e+00,  2.7698e+00,  4.7364e+00,  3.6557e+00,  6.7703e+00,\n",
       "          5.4121e+00,  2.0905e+00,  2.0015e+00, -3.0999e+00,  9.1086e+00,\n",
       "          4.4997e+00,  1.8954e+00,  4.0529e+00,  2.4821e+00,  1.1905e+00,\n",
       "         -4.0317e+00,  5.6983e-02, -3.8947e+00,  2.9962e+00,  3.8681e+00,\n",
       "          4.9308e-01,  1.3991e+00,  3.8501e+00,  2.1043e+00,  1.7045e+00,\n",
       "          4.3630e+00,  7.7115e+00, -1.8069e+00, -5.1281e+00,  8.9059e+00,\n",
       "          6.1015e+00,  5.5077e+00,  4.1643e+00,  3.6592e+00,  2.2524e+00,\n",
       "         -7.1478e-01,  3.6857e+00,  5.1387e+00,  2.4390e+00,  8.8072e+00,\n",
       "          6.9403e+00,  1.1679e+01,  2.4702e+00,  6.3682e+00,  2.1883e+00,\n",
       "          8.0996e+00,  1.1322e+01,  2.4897e+00,  7.4033e-01,  2.7549e+00,\n",
       "          1.0263e+00,  4.2829e+00,  3.1264e+00, -6.9391e-01, -5.7831e+00,\n",
       "          1.1789e+00,  9.3624e+00,  3.4107e+00, -2.1887e+00,  5.9787e+00,\n",
       "         -3.9359e+00,  1.6171e+00,  5.2939e+00,  9.7024e+00, -1.8476e+00,\n",
       "          8.3564e-01, -2.0675e+00, -2.3673e+00,  4.5139e+00,  5.4571e+00,\n",
       "         -2.3816e+00,  2.0507e+00, -6.2974e+00, -9.2804e-01,  3.9198e+00,\n",
       "          6.0577e+00,  6.8039e+00,  5.1425e+00,  4.7460e+00, -9.1035e-01,\n",
       "          2.2240e+00,  2.8314e+00,  5.3529e+00,  3.2687e+00,  7.7673e+00,\n",
       "          1.2799e+01,  6.6010e+00,  6.1264e+00,  3.9148e+00,  1.0120e+01,\n",
       "          6.2713e+00,  1.0444e+01, -4.8170e+00,  1.1029e+01,  8.4218e+00,\n",
       "          3.7815e+00,  5.8444e+00,  8.2536e+00,  6.0031e+00,  1.9003e+00,\n",
       "          1.6416e+00, -3.0008e+00,  7.5814e+00,  3.4477e+00,  5.7288e+00,\n",
       "          7.1073e+00,  8.4867e+00,  8.4105e+00,  5.9215e+00,  4.0099e+00,\n",
       "         -1.3571e+00,  7.8458e+00,  4.4592e+00,  1.0355e+00,  1.5760e+00,\n",
       "          4.3712e+00,  3.8860e+00, -1.5924e+00,  8.3033e+00,  8.2599e+00,\n",
       "          6.0332e+00,  1.2977e+01,  5.0995e+00,  7.4231e+00,  9.4058e-01,\n",
       "          1.1560e+01,  2.7923e+00, -9.8766e-02,  8.0633e+00, -2.6239e+00,\n",
       "          2.8151e+00,  1.2173e+01, -2.8192e-01,  1.1921e+00,  3.5963e+00,\n",
       "          1.6227e+00,  3.0317e+00,  8.4990e+00,  4.3715e+00,  3.7140e+00,\n",
       "          4.5632e+00,  2.3145e+00,  6.8065e+00,  1.2231e+00,  3.1610e+00,\n",
       "         -8.9764e-01,  5.3302e+00,  3.6475e+00,  3.8955e+00,  1.8493e+00,\n",
       "         -7.8568e-01,  7.5853e+00,  8.6734e+00, -3.9685e+00,  7.5852e+00,\n",
       "          8.4018e+00,  3.0679e+00, -6.3608e+00,  3.5792e+00,  1.2062e+01,\n",
       "         -9.8525e-01,  6.9589e+00,  2.0198e-01, -5.6421e+00,  2.7190e+00,\n",
       "          7.6262e-01,  2.9974e-01,  1.2903e+01,  5.4357e+00,  6.5245e+00,\n",
       "          1.0112e+01,  1.1982e+01,  4.9723e+00,  4.0257e+00, -2.0329e+00,\n",
       "          6.8675e+00,  5.2898e+00,  6.0616e-01,  2.8095e+00, -1.0162e+00,\n",
       "          7.4073e+00,  1.0379e+01,  3.8478e+00,  1.2390e+01,  1.1881e+01,\n",
       "          3.4890e-02,  9.5898e+00,  3.7880e-01,  4.6029e+00,  9.0111e+00,\n",
       "         -2.3542e+00, -4.2365e+00,  4.0823e+00,  5.9064e+00, -4.6997e+00,\n",
       "          7.7078e+00,  7.3990e+00,  3.4258e-01,  8.4034e+00,  9.1698e+00,\n",
       "          6.9115e-01,  2.8549e+00,  6.8383e+00, -9.6789e-01,  5.6571e+00,\n",
       "          2.1815e+00,  9.9146e+00,  1.5187e+00,  6.8646e+00,  2.9280e+00,\n",
       "          3.4000e+00,  6.5180e+00,  1.4245e+00,  3.5093e+00,  1.6306e-03,\n",
       "          4.4032e+00, -1.3244e+00,  5.2514e+00,  9.0368e+00,  5.1370e+00,\n",
       "          6.3643e+00,  7.3567e+00,  1.6848e+00,  3.7668e+00, -1.1062e+00,\n",
       "          5.4104e+00,  8.3821e+00,  4.4961e+00,  6.5000e+00,  1.3179e+01,\n",
       "          8.4451e-01,  4.6021e+00,  4.9657e-01,  1.0768e+01,  1.2219e+00,\n",
       "          2.2633e+00,  3.2009e-01,  6.1602e+00,  1.1872e+00,  1.4986e+01,\n",
       "          4.5885e+00,  2.9082e+00,  6.3583e+00,  4.2335e+00,  2.7769e+00,\n",
       "          1.3513e+00, -2.5710e+00,  4.2457e+00,  8.2464e+00, -7.1151e-01,\n",
       "          1.5227e+01,  9.2754e+00,  4.7706e+00, -6.1732e+00,  9.2593e-01,\n",
       "          8.0507e+00,  2.1795e+00, -1.6642e+00,  9.9256e+00, -1.8834e-01,\n",
       "          4.6009e+00,  6.8308e+00,  5.3643e+00,  7.1106e+00,  3.6495e+00,\n",
       "          6.6922e+00,  3.6506e+00,  2.2801e+00,  4.0798e+00,  4.2295e+00,\n",
       "          4.3631e+00,  5.2244e+00,  1.1463e+01, -1.1038e+00, -2.3109e+00,\n",
       "          6.4989e+00,  1.5154e+00,  4.1923e+00,  9.4599e+00,  4.4847e+00,\n",
       "          3.4668e+00,  4.1155e+00,  5.4102e+00, -1.3861e+00,  4.7537e+00,\n",
       "         -7.5527e-01,  4.9054e+00, -6.9753e-01,  3.7464e+00,  2.7589e+00,\n",
       "          4.5701e+00, -3.1375e+00,  5.3368e+00,  1.0140e+01,  3.1931e+00,\n",
       "          1.7649e+00, -2.6297e-01,  7.8749e+00,  5.9673e+00,  7.7763e+00,\n",
       "          5.4731e+00,  1.0127e+01,  1.0418e+01,  9.3092e+00,  2.2593e+00,\n",
       "          2.0138e+00,  6.7344e+00,  1.1039e+00,  1.9724e+00,  6.4212e+00,\n",
       "          2.6568e+00,  1.2826e+01,  7.4821e+00, -7.1722e-01,  8.5633e+00,\n",
       "          6.1068e+00,  9.7310e+00, -4.9118e+00,  9.1849e+00,  9.4386e-01,\n",
       "          4.8233e+00,  6.1523e+00,  5.5108e+00,  5.3380e+00,  5.7319e+00,\n",
       "          6.0613e+00,  1.0059e+01, -3.4868e+00,  5.3066e+00,  6.8519e+00,\n",
       "          4.3069e+00,  1.8221e+00,  6.6900e+00,  4.9349e+00,  3.4959e+00,\n",
       "         -4.2745e+00,  1.7045e+00, -1.2717e+00,  1.8298e+00,  2.8419e+00,\n",
       "          9.2525e+00,  5.4809e+00, -5.6337e+00,  4.2810e+00,  1.0777e+01,\n",
       "          2.8756e+00,  3.2824e+00,  6.6608e+00, -3.5669e-02,  1.0405e+01,\n",
       "          2.4195e+00,  1.2015e+01,  1.0100e+01,  6.3937e-01,  1.7233e+00,\n",
       "          8.7969e-01,  8.8920e+00,  7.7239e-01,  2.9164e+00,  3.4683e+00,\n",
       "          6.6055e+00,  1.4298e+00,  1.1072e+01,  5.4730e+00,  1.2584e+01,\n",
       "          4.2349e-01,  6.6527e+00,  1.1397e+00,  7.0250e-01,  4.9149e-01,\n",
       "         -3.5519e-01,  5.3425e+00,  6.8802e+00,  1.2612e+01, -1.8876e+00,\n",
       "          5.1371e+00,  4.4171e+00,  2.3988e-01,  3.8474e+00, -3.2990e-01,\n",
       "          6.4687e+00,  3.8654e+00,  6.6211e+00,  8.1147e+00,  8.2793e-01,\n",
       "          3.5706e+00, -3.9022e+00,  4.2293e+00, -2.8702e+00,  6.9979e-01,\n",
       "          1.6103e+00,  9.0968e+00,  3.9408e+00,  6.6844e+00,  3.0261e+00,\n",
       "          1.3605e+00,  4.1973e+00,  5.4302e-01,  3.9895e+00,  3.2046e+00,\n",
       "          5.8281e+00,  2.6495e+00,  5.6515e+00,  3.2545e+00,  3.0684e+00,\n",
       "          7.4540e+00,  1.0545e+01,  3.7005e+00, -2.5599e+00, -1.8779e+00,\n",
       "          6.3078e+00,  2.3386e-01,  1.8025e+00,  3.3880e+00, -6.0317e-01,\n",
       "          5.1040e-01,  8.9376e+00,  5.7107e+00,  1.0112e+01, -1.3891e-02,\n",
       "          6.2061e+00,  7.2830e+00,  4.3145e-01,  3.6964e+00,  1.1001e+01,\n",
       "         -3.5832e+00,  2.4656e+00,  8.7709e+00, -3.0202e-01,  1.2257e+01,\n",
       "          4.8423e+00,  4.9222e+00,  3.0268e+00,  7.1965e+00,  6.3967e+00,\n",
       "          4.0862e+00, -5.7594e-01,  1.2639e+00,  6.7316e-01,  7.7826e+00,\n",
       "          6.8982e+00,  8.5678e+00,  1.0723e+01,  3.1110e+00,  7.0943e+00,\n",
       "          8.8472e+00,  3.9822e+00,  5.9525e+00,  1.4886e+00,  6.8791e+00,\n",
       "          5.3350e+00,  5.3656e+00,  3.3842e+00,  7.9297e+00,  2.4924e+00,\n",
       "          6.9961e+00,  1.7753e+00,  1.0620e+01,  9.0364e+00,  8.9808e+00,\n",
       "          6.1558e+00,  2.4700e+00,  8.1604e+00,  1.0207e+01,  1.7782e+00,\n",
       "          2.2240e+00, -2.7917e+00,  1.9877e+00,  3.9906e+00, -2.5178e-01,\n",
       "          7.6409e+00,  1.4407e+00,  2.6756e+00,  2.2950e+00,  8.1595e+00,\n",
       "         -4.3099e+00,  8.6392e+00,  1.4159e+00,  3.0060e+00,  4.4703e+00,\n",
       "          5.7887e-01,  3.0632e+00,  3.9607e+00,  4.0061e+00,  1.1790e+01,\n",
       "          7.0575e+00,  4.7332e+00,  8.0195e+00, -7.9687e-01,  8.7009e+00,\n",
       "          7.0521e+00,  3.1888e+00,  2.0865e+00,  2.5377e+00,  5.3246e+00,\n",
       "          2.4421e+00, -1.2901e-01,  8.1681e+00,  6.7260e+00,  4.6135e+00,\n",
       "          6.2324e+00,  7.6854e+00, -1.0462e+00, -6.2083e+00,  7.4530e-01,\n",
       "          7.6211e+00, -1.9833e+00,  6.2758e+00,  3.7733e+00,  9.8907e+00,\n",
       "          7.7300e-01,  8.2246e-01,  5.8347e+00,  2.1488e+00,  3.6130e+00,\n",
       "          6.5770e+00,  5.5852e+00,  7.8161e+00,  5.1663e+00,  2.5401e+00,\n",
       "          2.5826e+00,  2.9020e+00, -5.4759e-01,  1.4645e+00,  7.7980e+00,\n",
       "          9.0552e+00,  2.9605e+00, -6.0508e+00,  4.4438e+00,  7.2370e+00,\n",
       "         -1.7623e+00,  1.1063e+00,  9.3863e+00,  4.4141e+00,  1.1387e+01,\n",
       "          2.2368e+00,  1.0225e+01, -7.4373e+00,  5.6300e+00, -2.9199e+00,\n",
       "         -3.7999e+00,  3.5764e-01,  1.4147e+01,  4.9183e+00,  7.5046e+00,\n",
       "          8.8796e+00,  1.8260e+00,  1.0736e+01,  1.3587e+01,  1.7342e+00,\n",
       "          6.2235e+00,  7.1740e+00, -2.6099e+00,  7.1897e+00,  9.6229e+00,\n",
       "          1.9348e+00, -6.6271e+00,  7.2484e-01,  3.2387e+00,  6.8979e+00,\n",
       "          6.7460e+00,  8.7150e-01,  1.0229e+01,  2.0268e+00,  6.5834e+00,\n",
       "          2.8032e+00,  7.0076e+00,  5.7578e+00, -4.4073e+00,  7.9164e+00,\n",
       "          1.3087e+00, -7.4768e-01,  4.0176e+00,  1.3801e+00,  5.5721e+00,\n",
       "          5.0603e+00,  6.5027e+00,  1.2203e+01,  8.2683e+00,  7.0647e+00,\n",
       "          5.9259e+00, -1.3167e+00,  1.1253e+01,  1.0883e+01,  1.1916e+01,\n",
       "         -7.6031e-01,  3.0698e+00,  2.9285e+00,  4.8406e+00,  4.8397e+00,\n",
       "         -1.0567e+00,  3.2607e+00,  7.7095e+00,  7.8717e-01,  1.8129e+00,\n",
       "          8.8503e+00,  8.3801e+00,  2.7218e+00,  1.1472e+00,  7.0479e+00,\n",
       "          3.2403e+00, -1.5106e-02,  3.3893e+00,  2.2801e+00,  8.3147e+00,\n",
       "          4.9688e+00,  1.4004e+01,  1.0653e+00,  5.5011e+00,  4.9926e-01,\n",
       "          5.1120e+00,  4.6769e+00, -2.8194e+00,  8.4678e-01,  3.0332e+00,\n",
       "          4.0051e+00,  7.1576e+00,  4.6979e-01,  1.1379e+01, -1.2892e+00,\n",
       "          1.1801e+01,  8.6953e+00,  3.1760e+00,  2.6228e+00,  4.6295e+00,\n",
       "         -2.7755e+00,  1.0831e+01,  1.8828e+00,  1.6825e+00,  1.0717e+01,\n",
       "          4.8874e+00,  3.5066e+00,  1.7252e+00, -1.0312e-02,  4.6654e+00,\n",
       "          6.2478e+00,  6.9388e-01,  8.5780e+00,  5.2016e+00, -1.2921e+00,\n",
       "          3.9075e+00,  4.6256e+00,  1.2500e+01,  4.5179e+00,  3.8376e+00]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_inputs = 2 \n",
    "num_examples = 1000 \n",
    "true_w = [2, -3.4] \n",
    "true_b = 4.2\n",
    "features = torch.tensor(np.random.normal(0, 1, (num_examples, num_inputs)), dtype=torch.float) \n",
    "labels = true_w[0] * features[:, 0] + true_w[1] * features[:, 1] + true_b\n",
    "labels += torch.tensor(np.random.normal(0, 0.01, size=labels.size()), dtype=torch.float)\n",
    "features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-means",
   "metadata": {},
   "source": [
    "使用 `𝐮𝐬𝐞_𝐬𝐯𝐠_𝐩𝐚𝐥𝐲()` 和 `𝐬𝐞𝐭_𝐟𝐢𝐠𝐬𝐢𝐳𝐞()` 两个函数来可视化所生成的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "medium-patient",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAACnCAYAAADqrEtMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAp30lEQVR4nO2dfXRU53ngfy+SBjQSoNEHMh8CfSIqe0HBssFYmPDlEzesnWYD2eRkTd3NYu85oZRy9qROvXU+3NBt1nGpz54aNo0Xn7ZpTDetvSS0NpgYBAEj24BBQdYnCAFiNDMSaGbEaKR3/7jzXu6MZqSRNELS+P2dwxlpdOfedzj3uc/zPp9CSolGo5l8TJvoBWg0muho4dRoJilaODWaSYoWTo1mkqKFU6OZpGjh1GgmKakTcdHc3FxZWFg4EZfWaCYVH374YaeUMi/a3yZEOAsLC6mtrZ2IS2s0kwohxOVYf9NmrUYzSdHCqdFMUuIWTiHET4UQN4UQFyzvfVcI0S6EOBv697vjs0yN5rPHSDTn/wG+EOX9V6SUlaF/v0rEotzeAHvfb8LtDSTidJPuehpNPMQtnFLKY4B7HNdisv9kC7sPXWL/yZZ7cTkO1Lax+9AlDtS23ZPraTTxkAhv7beEEE8DtcAuKaUn2kFCiG3ANoCFCxcOc0oR8Tq+bK4qCHvVaCYDYiQlY0KIQuCglPKB0O/5QCcggR8Ac6WUfzDceaqqquRQoRS3N8CB2jY2VxWQnWGLe30azVRDCPGhlLIq2t/GpDmllB2Wi/xv4OBYzqfIzrDx7JqSRJxKo5myjCmUIoSYa/n194ALsY7VaDQjYyShlJ8BvwHKhRBXhRD/GfhLIcQnQojzwFpg5zitM6Fo76xmKhC3WSul/FqUt/82gWsZEyPZpyrvLKDNZ82kZUJya8eDkQhcpHdWO6A0k5GkEc6RhEMiHU7RBFsLrGaiSRrhHIuHN5pga9NXM9EkjXDGi9sbCGUeCbauKgSIqiF1YoJmovnMCeeB2jb2HGkEwG5LAYiqISM1sTZzNfeapBPO4YRoc1UBvkAQEGyuKsDjC3Cq2cWGivyon1e/+wL97DnSAGgzV3NvSLp6zuGS2LMzbOzcWM7OjYvJzrBxuK6Do/VODtd1RP383b2n5PknloR5eHWsVDOeJJ3mHGqvGE2rRh6/oSKf4w2duHru4PYGwv5u1cT7T7ay50gDvkA/OzcuHnZd2izWjJSkE86hvLbRPLDqeKUJfYF+aho7qWnsJCdzOs+uKYlxPhnxOjTj5f3VQp+8JJ1wDsVQyQdKeHasL2XbY8VcbO8296EK6/FbVxWF3hWmaTvcXtf6mih0yCd5+UwJ52AtGTQ9t1bh2X+yhRNNLt4+287OjeXm5yMFwR/oZ9/xFvyBIDmZ06MKSZOzh5cO1vHCpopxER4d8klepqRwjsWUc3sD7HrzLEfrnexYX2Y6ecLN4ejF3pGCcO5qt/n6N994MOxvipcO1nG03gnU8fozDyfkO1jR5XXJy5QUztGYctaQyNF6J2vL89i6qjCqYGxdVYjdljJI0CIFYdmC2ZxucbNswewwrfzKu58Ckq2rinhhUwVQF3od/B18gX7zWiMRUr3XTH6mpHDGY8pF3rzWPaVVW8Y6Ph6hf+7zpeRkTg/bwyqtDHD+ajcvb6kM05iR38EXCA75oIklhHqvmfxMSeGMR3gib95YIZFYx49mHQdq2zha76S6NBcpJUfrnew/2YLdljroulZNq/4ez/dQ6L1m8jMlhTMeIm/e4QQ62s0eK1soloBvqMjnVLOLFzZV4LDbTDN6LBrOuq6RaHdt9k59ki5DCEZ3Y6qbPZrpGJktFC37yO0NmM6fw3Ud5vmerJzH2vK8QWGZWNcYal0jaRmq231OfZJSc8ZjosYjwJHaNFKLWatblEm7tjwvTPuq9MCVxR2UrMkc9hpDry3+lqHa7J36xC2cQoifApuAm5bWmNnAz4FCoBXYEqtv7XgQ6yaO58aMR4AjTUfr73vfbwqrbnmoMJuSvAy2rysLM4GVxozVdSE7w2YmQUQ6ryLXpkrcQOL2Boa0CnSIZeoz1nEMfwIckVKWAUdCv98zYplukSZqtCT1DRX5Q5qbilgJ7purCtixvpQd68vYXFXAq+810OT08up7DWFre+lgXdjDI9qaI9/bXFVgepSt18/OsGG3pbDnSGPY53USfnIykgZfx0JNpa08BXw+9PN+4NfAtxOxsHiI13SLlqSuzM2lC66FxTQjNXEsLaaqWxRbHynk3NUuvvy5+ex9v8l0Dh2td3Kgts38bLQ1G2Vs/bh67vDDX/2W9LRpbF1VRHaGjb3vN7H70CVONbt4eUul7trwGWKse858KeX10M83gKHVUIKJ33QbnKQeLc4Igwuv434A/KYVt7ePvzpiaFCAl7dUmsJuXXOkGXtXIzaYx9ltqWYISAn5rjfP8vKWykHfWe8vk5OEOYSklFIIEbNEY2SzUhLL1lVF2G2pbKjIZ+/7TWGhiGhxxsib3BcIsv9ka8yMIsDMBNq+rowzre6Y4Y7IRAXrQ+DvTl2mzeOnwJEeFgJ6eUul+RmrFlbo/WVyMlbh7BBCzJVSXg91f78Z60Ap5T5gHxizUsZ43RGhbl5lIsLgkjFF5E0e2dYklhCU5GWamUDLFzmiHmMVzOrSHHyBoLmXzM6w8cQDc9l3vJknHpg7KGEhmhbWJDdjFc63ga3AX4Re3xrzisaR0Zh/kW1NxoI13LJ0QZZpxirN/dznS0i3pWD1xlq9u5Hm8HihExgmByMJpfwMw/mTK4S4CryIIZRvhkYzXAa2jMci4yGeG2o05p9y/Izkho03xGO3peDqCbDnyCV8gSA7N5Zjt6Ww+9Alc89pTZD/8LKHmsbOuLsvjBbtYJocjHUcA8D6BK1lTIz3DTWS81uPjdR21qbVvkA/566qsLAw39u2ughfoB+3N2B6ff2BIDWNnaFjh94VjDTtMBLtYJocJE2G0HjfUNYeQ9aSsMib/a6AFZuOJBXGAYm/b4D0tGn4+wbYd6wZwCxfM/a3Dawtz+NovdNs3WmEfLLYtrqYuuvdPFk5f8i1Rj5IhnuwREuMsBala/N2Ykga4Rwvj2Xkns/qaVWmpxUlYCV5GTQ5vWaJmrXrAsCjJTnm6wubKjhQ28ZDhdmsLc9j+7oyli6YjS/Qz5OV8wDjofDiWxepaXTx8w/ayMm0xd0SZbgHVyzh1ebtxJI0wjlW4qmbBMySsAcXZQ1KydtQkY8vEKS6NJeaxk7WlufxZOV8Dtd1mNrO4+2jydnDrsfLeSwUclHXWFGUzekWNwUOO82dXmoaO/H39ZOTYePts9dMs7buejc1jS4gutCM9EEVq/JFm7cTixbOECOpm4wlwG/WtpnacnVZbpjgAezcWM7e95t449RlbO818PKWSgDaPT4Kc+z47vQBcKzBSavLB0Btq5uPrnTx9MpF7Fhfhj/kOX5wUXZUoTES8luxmt3DacDInGHrsVpjThxaOENY95TWfdZwcVD1WZXFY+wf7+5FI4V7Q0U+b4ZCKvtPtvDh5S5TIy6dP4uSvAz++xcr+LitC5CcajY0ZHNnD3/3pZWm8GxbXcyuN8+y9ZFCflLTQsXcmXz14YWWnkXhWUbWNcTz/6C15cSjhZPoLTJhZB0RrL2CIj2k1vMcruugyellbXkeICweWPD4+mjz+KnvuM2TlfN46WAd/3VNKXZbKy9sqsDtDeDyBni0JIdzV7s43eLm3NUu3N4+aho7OXLpJk1OL9WlOTy4yBGWZRRvjFRnG00etHAyOPRhfY2GdY95uK6DzVUFgxLprQ6gDRX5ZntM6/k9vgDHG5zc6O7lvtkz+OhKl1kPanU8qcyjV96tNz2882bPYEWRg2+sWMRf/ls9/QOSJqeX7Iw0vlldzMdtXew/2RK3aauZfGjhJFwgR9KfSJmyqjUJ3E2kV203N1Tks+2NWpqcXvr6L7C6zChTO1DbhqvnDh9d6QJgmhBUl+aamnf7ujJaOr3kZU7nh7+sI92Wij8wYK7hWncv5ffNpNHZQ5vHD0B2Rhpubx8/+GWdmXz/4WUPDy7KNr2+2lydOmjhZPTezYcKs7ni9pmdDp5dU0KTs4fzV7t5snIeJXmZ7H2/iSanl5K8DIrzMtl96BLHG5zUNLoozLED4LCncbXLz9UuP2+fvcbOjYs50+qm1eUzHUMAO9aXsWN9GR7vHZo7fbywqYK3z14DoLo0lz/euJhX32tg+7oy/vXiDd65eIOaRlfIsyvDStwgugWg45mTBy2ccRCre8GuN8+a+0clsJFtSaxaWfX+qZg7m7SUaRytd1KSl8GPvrKMl9+p50STIUTqeF+gH3+gn96+IM2dPtYszuNfL9ygvqOHZQtm47DbwnrsWhPk09Om0eryUeBIp83jxx8YCOs+X5KXaVoAe4814fYanmJt8k4etHDGQbT9mkpiL8nLME1RGLrrnypdU/vNK27D3D3T6ubVry8fVHVit6WYjqGaxk7SUoS5Dz3d4g7rmRu5VkPLlnKq2U2bx8+5q128U3cjpImN7vObqwrM8E9JXsagOKe1k8RwziSdLJ94tHDGQaxYp9pzvnSwjpe3VMbsCaSwCuqBkFCoVinKvNx/shV/IMi5q92cbnGbJvDs9FRcPXd4atnckONoDhsq8tn+Dx9xosmFLxDkycr5HPvUydMrF2FoYMHpFjfZGWmcbnEDmA8Txfrfyee+Wd18/0sPhHVegPAH0XDOJO1wSjxaOOMg2p50qCLoeG5Uq8BHMy8VxXmZXO/upcnp5Xz7LUu45RYvvnUhZAqDv2/AdDzduNVrJkNUl+ZQ0+hiRVE2K4uzzeloapDTvmPN7FhfGtq7SjOTKVrxeWRGlPXho+OjiUcL5xiIVQQ90hvVal4W5th5vCI/FMf0UH/jFg8uzMJ5+w63eoM47Gm0efycbjGqWWanp1KSl0mX9w5NTi+z01P571+soL7jNpurCvD3DVDT6KI8fyZ2Wyoe393+usqj7Av0D6otjZYIr4j28NHx0cSjhXMMjHSfFS3Z4VSzi+3rysjNtJGbOZ1vf2EJZ1rd/PDLS3nxrQvUNLpMQVxbnkeBw8759lsAZKWn0eXv46MrXTQ5ewDo9gd579JNvv+lBwBITzMaLDY5e3jj1OWITKZCwGiAtm11Mem2aXElYmgteW/QwjkGRlLNEdk7yLpnPdvWhcfXR3VpDmda3eZnH1zkoKbRxfKFWdhtKWx9pJDv/r+LABQ40nmkOJtjDS5u3Oql2x8kdZogOCA51mBco8nZw4eXPTy9chEzbClUFTpYs3gOgLnvVGt6/okl5lpVDemGivxBzbOjaVLN+KCFcwzE0iDR3o/sCB+5ZwW47PLxzeqZppPIYbdht6Wa2UYXrnXT5QsyKz2FNo+ftg/bmTnDqPmcOSOF7zzxO/zonXq+++/vx+0NmHtQtWd9/oklvP/pzVAmUzsgzCob61pVOAjqWLpgdlw9lDSJRwvnGIilQaK9H5mFpI57YVMFff0XuOzy0ebxm9k9KqlBFT2fv9ptCvGM1FRu0c/0FMHt3n4Abvf2c/D8ddzePiN17zetZjqfSqR39QSovWx4bVXRN8CDi7LCzHJrcv7SBVnsWF9KInooaUZGQoRTCNEK3Ab6gaCUsioR500mYgny4boOahpdbHusmIvt3cx3pHPfrBk8VJhtVscAlM2ZyUdXPHT7g9y8fcdM1QOYkTqN3uAA/r5+Hi3JwR8aEKyO2f+bVsrmZLLvuGUAkjSSHXasL7OMeTB4++y1UAJ97pDtQIci1n5cx0PjJ5Gac62UsnP4wzRWwjOIWk2vqe29Bo7WO/EF+jl/tcvUmrPTU3mqcj5fqpzPXxz6Le1dftq7einMsZt5ulWFDrPVSVZ6GkfrnXT774ZoCnPs9PYNsO94C8sXZlHb6ub7X3qAkjw1aMkQ3Iq5M8PS+4ZK84s1rBh0d4XRos3aCcaatGAUUhutS7Y+UsgVtw+PN8DReieFOXZaXT66/UHmZ6WzfJGDR0pyTWHOzrDx+P33maMcgLD97I3uXsDI4zWyhIz3lUC/+NZFvvfU/bx00GiMbbel4uoJsPvQJY596uREkyss0V8lXSiGGlZsRXt64ydR8zkl8I4Q4sNQZ3fNCFA3drotleefWMKux8vZGcrbre+4xfNPLOHHWyp5tCSHbY8VmwXhSpjBELKL7d2o8YDK4VRdmgsYVSzZGWl4fH2U5GXQ6vLxaEkOyxdmAYaW/LN/ucDReicvv1PPs2tUD10IDkh2rC/lhU0VpkaOHB61ucoY7KS6Bkabd6rWFe19zWASpTmrpZTtQog5wLtCiEtSymPWAyZyHMNkYrjsmuwMG8+8/gEen2GGLitwmN3qTzS5sKVOY/+JVt44dZml82ebie0OexonmlxmxpBK3/veU/fz8zNtvHPRyKtVDcRefa/BDKf82b9cACEomZPJiSYX98+fDRgjB5VJvW7JHEryMqMmXajvBII9Rxq0VzdBJEQ4pZTtodebQoh/Bh4GjkUcM2HjGCYTQ2XXqFaU29eVmV3mv/rQXcFVZqUqNTvf3h36vOH4ebjQgS01BY/3Dm+cugIY4Y+cDButLh+Lsu3kzZzOjn/8mDaPn7L8Nho6bptCve2xYnP0oFpXNGGMnB1zN9m+NOzzoB1AY2HMwimEyACmSSlvh35+HPj+mFeWpFgD/Ap1A6s0uuefWMK6JfnsPnSJw3VG6ZkSlP0nW/B4++gfuGkOPVKac+7sGbx17jotnTMAw/GjrqPSAy+779aHnmvzcLrFw6wZqdzqDYKU+AL9ZgcFuDsS0eMzkijK5sxk33GjG4PSkKq8DeSgapZoQ5s08ZEIzZkP/LMQQp3vH6SU/5qA8yYl0cbQR2qeDRX5/PyDNqpLc8KEODvDhj8wwBunLvP0I4uYn5WOq+cO+4634PH18f6nhrO8vauXAkc6rS4fL751kYq5M2lyelm+MIsb3b1c6zb+Xn7fLE63eLjVG2RFkcOshFGo2KovEOSts9dodfnwBYLsWF+Kv28gbBBT5BgJ9b1UWd1wQ4o1gxmzQ0hK2SylXBb6d7+U8s8TsbBkJdpE7c1VxiTrrauKeHZNCYfrOth3vJmaRheH6zqAu9Or1fiGZmcPm6sKSLel8vTKhVSX5vKDp+4nKz0t7Ho1jZ3UXb8NgPP2Ha51G2EXpW1Vc2tVXgaEYqUDHK13sqLIwalmt9mRwR/oBwRIyZ4jjWYBufpeKj7r9gbYXFXA2vI8mpxe83to4keHUu4x1tS4yHCEItJMtJqHK4qyqS7N4XtPPWB2l68uzaVi7kxeP9lKl7+P+VkzaPP4Q2ViOWbBtjIvszNsPF6Rj79vgPvnzaKqMBt/IMjpFjcrirKpKnTg7zP6Fd3ovhNmCp9vv8X59luml9fj7QuVnxmJD1fcPrN/0bNrSvTowjGQqFCKJk6UNlGTqtV+c/ehS2Z4wphstpidG8tNh4tyBBnaTeCwG/HRFUXZ1DR2su94ixmz7LljhFiWLZiN3ZaCw27sV5WW/OhKF3XXb7PvWHMoa0iSbkthx/oyloVyaQ99cp0VRdlcdvtw2A1tPDv97rNchjKMLt24ZVbXLMq20+T08mhJzrAhFYWyCNzewDj8b09ttHAmmOFuNuXYscYLlVkbS7tsripg2+pi+gcMgahp7ORAbRvZGTZSpxlxTSU4Dnsa3f4ga8vzSLelmkKfnWHj1a8vZ9vqIqpLcynONTy+yoTdc6SRt8620xs0NGabx09aimBteR4eXx8FjnS6/UGWLzRybR8qMgS9cqGRjXS6xc1ltxGquX/ebPYcaTBN3qGIfDBp7qLN2gQTT3paZIjCmiUULUUuO8NGw83btHn8FObYeapyvinIux4v58Y/neOP1pfxi4/bw8beGxge2CZnT2jfZzSyrphbzLbHijl7xWMmw7e6fOTfuG1OM/veU0ZNqC/wCb+9btSQ2m2p5rzSnNC6AXMExJrFc/jjN8+Gri2G/f8yTPhgmKbVGGjhTDDxpqfF6i6gYpkQLtzWjvIOu82ssQRocnr5xcftIS9wjhkztSYGqGSCAke6cUIBDR23+aDVcDBNT53GneAA/kA/6bZp/PXXluPxBfj9n34Q1hf3e0/db67JF+jntV83km5LNWOe3/jJaVpdxuwXlVA/VKzT8PSmhjy9OnnBihbOBDPaQmTrLJWVxR2DhLskL9Ps/L73/SazxnLbaiNx4KHCbALBAVzeQNg+dtvqYh4tyaHAYefRkpy7GURS8sKmCrx3znPx+i28d4zSs/Pt3Zxv7+ZUs5uOW72mYM5OT+UryxfgsBujJv7wZx+HjZI4f7WLl7dUUpybQU1jJ4HgAK2dXqN5tjfAvmPNuCzadqiJ3xoDLZyTBKtQO6psQ2bVbK4qMJPRVWuRXW+eNTN9Gjpus31dWWgeC2EZQFfcRt1ob98Ah+s6eKQk19SeGdOn8cC8LE63uM2wSoEjnXlZM1i2wMG+48003Oxh6YIsUzD/3byZ2KenhQYzteLIMJxH17p72f6zj2jv6uW+WdMBONfWZZ7X+gDTnRWiox1Ck5DhnCTKuaNio8qbW12aQ3VpLkfrnbwaKjkDaSbMp6dNMzVhfcdtdh+6hMcXYH6WkVGUlW7j219YQnXp3cG+b32rmr/5RhXpthRWFDk4Wu/kepefGanGrWOfnsbK4uzQyoyxgyuKHADc6jXyg2/cumP+fcf60qgacihH2mfVo6s15yRkNN37rK/KsbSyuANfoJ8TTS4eW5xnOZ8w45rHPnXS3tXL9FRBe1cvL/2yjp9sfchME/zm/jM4b9+hzeM3ExzePnfN9OqW52eGNcvOzrDxN9+oMuOyBY508mZOJy1FcLrFw7ol+VGtgaEcabF6MiV7zq4WzknISIcpvbylMuoM0ZI1mbi9gbBxDUrTPlk5j4vXbnGiyXU3txbMLn52W6q5rwXDYdTl7zO7LigcGYbJ6gsE+at3P+XSjVssuW8WZXMyWbogC4A9RxrYsb6UlcW5YSl/VoZ6IEX72/6TLew50ogvEBw0AyZZ0GbtFMWazBBp/lrNwMgkACXUh+s6zM4HSjCnp06j2x/ktVB7FLVXBCzx1LvpgSuKHDxZOY9db55lz5FG3jh1mQ9aPbxx6rLZEmXrqkLT/LbbUthzpNFc71DrtGINNd01bUXEa/KhNecUJVY5F9wVQF8giN2WGhY7tWqh7f/wEWA4fb68fD6nmo0eue9cvMFXHyogLeXus9sb6CdlmqDj9h2L9hT82b8YXecLc+zMmpFmlrEBeHxGW01/3wD7T7YM6iY/kpYlkcdaBzglK1o4pzCxzN+HCrMpycvA4+tjz5HGQbFT1a+oZI6hOVX/oCZnj9lO86WDdWbSgz0thbobt80Mpd7gADNSp4V5dFtdPqpLc1lR5DCbYB+9dNN0QBkIdm5cbGpMlfwfj4ANNSAqWdHCmYT8+N16mpxecjNtZgnayuIOs72JdfzCjvVlHK7rwFFlM8YCPreKA7VtPFSYjS/QTyDYT6gcEIAcexpBKen2322RMi8rndI5meaIB1Xh0ubxMzs91XKsIdxWLbihIp9db54Ny2yKZdrGEsZkdQ5p4UxCKubOpqbRxbIFjjDnkJogtmN9aUiIJCBDJnA/Hu8djjV08uMtlZxpdYfVdqoGY65Q+5QVRQ76+g3Ttjx/JjPSplGWPxOPL8C1LkNbqnER6nh/YIBX3v00bMq28upGVrOMhGTt6KeFMwl57vMl5GTaTE1pzd+F8MbWhjfX6CqvWpv8t386x4HnVuHyBjjT4kIIwQPzZvH4/akgMYf5/vDLSzlc12EKhjUDKcueSpevjxVF2aROE8x3pJsdFMDoouDxBSjLn0kgOMCux8s50+oetObhcHsD+AL9MeOnUxntrU1ClAmoBEeVpg3lEV2zeA6fKzAahv3oK8sAyMmw8djiOXx0pYs3Tl0hJ8PGd774O7R5/NQ0dvLiWxfxBYJmbWdJXiYrioyEhAxbKttWF7OyOJsTTS5ONxtaOCs9DX+gn92HLvHiWxfYd6yZqsJsli9ysLmqgJcO1rH70CU2v3bSDOvEQtW5Gk3FUpPKpAUtnEnNUOEWhTIJX32vgY/buimdk0lhbobFVJTmlGylmVSLzIq5M9lzpNEMb9R33KI8fyaz01Np7+rll59c41Szm6dXLmTN4jwKHOl0+fs4dOE621YXUTHX6PLn8QV45vUPeO3XjWaneuWUshKZKRQ5fybZSNQ4hi8Ae4AU4CdSyr9IxHk1Y2OocItCdV3wB4L09UuO1jvZ/NpJfvSVZWZCvbWN5t73m3io0NCOq0pyOXLppjlX9HSLx/TUgtHLqL2rl86eO+Z4hzaPnzaPn4abPby8pZKcTJuZJ9zXL3n+iSWU58/kB780mltbiRYiAszJ4NohFIEQIgX4X8BG4CpwRgjxtpSybuhPasabeLyYqjmXyuK56jEcMz9+t56/++ZKnnn9A7OtysriHHYfukRJXgZNTq/pxFlbnmfOYnm40EHlQgddvgAnGjvJnzWdF754v7mf/PkHV6i7biTmqzRDlzdAcGCAirmzzGSDJqeXV99rCGvloh4wLm+APUcMJ9bOjYtNRxdoh1AkDwONUspmACHEPwJPAVo4J5h4vZhWR5E/MMC+482myRlZRwqY2jSysDsnc3pYY+z2rl5mpKVQmJvB8kVGMvx3vnhXA1vrV6tLc9h3vJl0mzFOQr2//2RLWN7us2tKeOXdegBqW91mIzHr90gWErHnnA9YNzRXQ+9pJpjh2p8orI6irz5s7FO/+nDszxTmZvD6Mw9TmJsBGHvGSA39wqYKU8NG2++qbn3b15Xx/BNLzIcBCNMcf/6JJYAwnVpNzh72vt/Ek5XzWVuex4kmV9RzJ0sVyz0LpehxDPee0WTRWPvqOqpsZsaQ1awFQxOr5PPjDU5qGl3m+25vwGjv+XSVOZ1MZQS9fdYY2gtyUOeGnEwbDxVm89W9v0FKye7/sBSH3WaZslZnDlJ6YVOFWZQeaSEkS9wzEcLZDlgfswtC74WhxzFMDcJHEraYzh7lEArvVm9kDlXMnc2Di7LNipPIihn1+3uXbpqJDdFGPzy7poRnXv/APOalg3W8/szD5jmM69aZDw8leJFmrbWrxEhippONRJi1Z4AyIUSREMIG/Efg7QScV3OPiF0dYgjfU5XzKcnLNLWqahCtKk6e+3yJWXGy682zpska2V1Qpe+B8aMSLqsJun1dGQWOdD5XMJvt68rY+34TYByrBikNZ6pHxnmname/MWtOKWVQCPEt4N8wQik/lVJeHPPKNPeMWMXM/kA/1aU5rFmcZ5ql1k55VqyDlpYuuMbSBVksXTA7zJGzoSKfrX/7AVe7/ETm2Sote6bVyMn98vIFvPxOPSeaXMPWbMZa/1TPHErUlLFfAb9KxLk0409kiCWat/NAbZsl3e5Ts2eQtVMeECYUxqClVk41d3K6xcOO9aVkZ9jCrve7S+ey71gz5652m55WJdQq4b4wx86xT2/ycZsqPxNh64oUxFjrV0Oh4k0DnGyxUp1b+xkk8gaP5jjaXFVgOnoq5s5kdVlu2M0f7WcVM1WJCGqkw/6Trew50mCMmAh1ij/d4jaFQeXXbqjI56WDdbS6fLS6MEcaqkR567XUq9sbCGsTGuu44bCucefGxXF9ZrzRwvkZJJ4bNzvDxl9/bXlUbWI1HRWGkLTiDwRZUZTN6RY36WmGS0NN4D7V3MmyBUa8s7o0x/S07jtmaOjv/OITyvNnsnxhFqnTBJULHew71myOQVTrUp9Tr6qdimrPmZ1hG4WnWka8TjxaOD+DxHvjDnecVQMDlhrRUtYtmWMKf7rNuM1Ot3hYWZxrOnSUoCkNrVpyVpfmUtPYSWWBI8z5ox4Ata1uTjS5zJCKLxDkw8se0zSOtubhzFZrk7LJghZOzaixamCPL8Dxhk4q5s5k66qiMAFQnd+N1pmFg4SjYt5sAsEBlsydhcNuwx8IUtPYSbpt2qCu+OoBUJKXYYZU1HiIoXKIh4t9TsbOClo4NaPGekMfqG2jprGT1WW5YcKnhCaaUIKx11Nm7SMlOdhtxh4z3ZYCiLBOfRsq8nnv0k36+gd4YN5sNi2dF3fbkqmY4qdLxpKce5XKFitVcPgpYsYezxhPKMzOgEZrzoawzx2u6+B0iztUX3oZuy1l0IMgGdL2FFpzJjn3KpUtlubaUJHP8YZOXD13zEln1n1f5F4vsqNe5M++QBB/3wDpadMGZQCNtDH1ZEcLZ5Iz0ebc4boOaho7qWnsNJtYu3rukJM5PaxlJzDIYWMVIhUyUYKpmmOr/kd2W0pYfWdk2t5I/h+anD28dLAulLyfmdD/j5GghTPJGaujY7TBefU5I6uoH5D4+wY40eSi7vptahpbwlp2AmGF1Op66jy+QDCsA71V27p67oRilEYmUbT6zpH8P7x0sM5MtFeT3SYCLZyaIRmtOWj9nArqq4G7SmNaxx16fAFONbtCU7YHV5ioVilKc4bXd34KgD8wMOJ+uNEePtYa1olEC6dmSEZrFkf7nFV7qaQC9ar6AZXlz2RteV6YgPlCSQyRIRqF6v7uCzUOg+EHHt3VyHd7+Jprs8xCnUi0cGqGZLRm8Ug/p4TYFwia8cuSNZkxJ19HCp2qCY10KEXuSyOdR4+W5LBjfdmkDLFo4dSMmkQmi4cLWGpUj200oYOh95VWobceb024f2xx3qRJdg9DSnnP/z344INSM/V57deNctG3D8rXft2Y0PO6eu7I137dKF09d8Z0zHDHj/Qc4wFQK2PIidacmlEzXmGaeJxQkVpyOC0+GdPzhkNnCGlGzVAd5EfLaIuk959sZfehS/zhzz42G4ENlyk0fPbSxKKFUzOpUHWVqgtfLAan6hlpgMaYiAtxCV283QknCi2cmgkllpANV1cZqfW2rioK5ecaDcd2rC+N2k7Fymg1/73K4dXCqZlQogmZGlMfi2imb3aGjVe/vtzScGxw4vxQjETg7pU5PCaHkBDiu8B/AVQO1nek0U9Io4mL0UysjtUfyPrZkTqrRpIJda/ylRPhrX1FSvk/E3AezWeQ0Uystla6WOs94z1vtPOPRODuledXm7WaSUss81FVuuw73sKB2rZR7wGt57fuPydLXWgiNOe3hBBPA7XALimlJ9pBehyDZqTE0mZqbCHIqOMYxnr+WOe71+0zhZRDe8WEEIeB+6L86U+BU0AnhmvtB8BcKeUfDHfRqqoqWVtbO/LVajRRSLTQxDqfKkV7/oklCTNrhRAfSimrov5tOOEcwUUKgYNSygeGO1YLp2YqMh6acyjhHNOeUwgx1/Lr7wEXxnI+jeZeMtK9ZbS46HjuT8fqEPpLIcQnQojzwFpgZwLWpNHcE6I5nEYqbOMZ8xyTQ0hK+Z8StRCNZryJd0bMSJxL4xnz1KEUzWeGSC0XGT555d1PcfUEwjKPhtOk45H8r9AlY5rPDENpOWs3eTUdTb0/US01tebUfGYYSsttriqgujQ39JsxsWyiZ3xq4dRoUFPVPhdKui8E7mpTuy11QtqYaLNWowkROV5wohtya+HUaCxE7jEnsrWJFk6NxsJQ2vJe59bqPadGY2Eop9FIEg4SkTmkNadGEycj2YMmIgSjhVOjiZORFFknwpmkhVOjGQcS0S1B7zk1mkmKFk6NZpKihVOjmaQkrBPCiC4qhBO4fM8vPHJyMdqwJCvJ/P2myndbJKXMi/aHCRHOqYIQojZWC4lkIJm/XzJ8N23WajSTFC2cGs0kRQvn0Oyb6AWMM8n8/ab8d9N7To1mkqI1p0YzSdHCOQxCiB8JIS4JIc4LIf5ZCJE10WsaK0KILwgh6oUQjUKIP5no9SQSIUSBEOKoEKJOCHFRCLFjotc0WrRZOwxCiMeB96SUQSHE/wCQUn57gpc1aoQQKcCnwEbgKnAG+JqUsm5CF5YgQo3O50opPxJCzAQ+BL40Fb+f1pzDIKV8R0oZDP16ClgwketJAA8DjVLKZillAPhH4KkJXlPCkFJel1J+FPr5NvBbYP7Ermp0aOEcGX8AHJroRYyR+YC1WvgqU/TmHY7Q/J7PAacneCmjQpeMMfQkNSnlW6Fj/hQIAn9/L9emGR1CiEzg/wJ/JKW8NdHrGQ1aOAEp5Yah/i6E+H1gE7BeTv1NejtgrQBeEHovaRBCpGEI5t9LKX8x0esZLdohNAxCiC8APwbWSCmdE72esSKESMVwCK3HEMozwNellBcndGEJQgghgP2AW0r5RxO8nDGhhXMYhBCNwHTAFXrrlJTyuQlc0pgRQvwu8FdACvBTKeWfT+yKEocQoho4DnwCDITe/o6U8lcTt6rRoYVTo5mkaG+tRjNJ0cKp0UxStHBqNJMULZwazSRFC6dGM0nRwqnRTFK0cGo0kxQtnBrNJOX/Awe0X0yQTpyrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 252x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 设置图的尺寸\n",
    "def set_figsize(figsize=(3.5, 2.5)):\n",
    "    plt.rcParams['figure.figsize'] = figsize \n",
    "    \n",
    "set_figsize()\n",
    "plt.scatter(features[:, 1].numpy(), labels.numpy(), 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-clerk",
   "metadata": {},
   "source": [
    "##### 读取数据\n",
    "在模型训练的时候，需要遍历数据集并不断读取小批量的数据样本。这里本实验定义一个函数 `𝐝𝐚𝐭𝐚_𝐢𝐭𝐞𝐫()` 它每次返回 𝒃𝒂𝒕𝒄𝒉_𝒔𝒊𝒛𝒆 (批量大小)个随机样本的特征和标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "public-gasoline",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 2\n",
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples)) \n",
    "    \n",
    "    # 样本的读取顺序是随机的 \n",
    "    random.shuffle(indices) \n",
    "    \n",
    "    # 最后一次可能不足一个batch\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        j = torch.LongTensor(indices[i: min(i + batch_size, num_examples)])\n",
    "        \n",
    "        # 按行选取\n",
    "        yield features.index_select(dim=0, index=j), labels.index_select(0, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-russian",
   "metadata": {},
   "source": [
    "##### 构建模型\n",
    "在构建模型之前，需要将权重和偏置初始化。本实验将权重初始化成均值为0、标准差为 0.01的正态随机数，偏置初始化为0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "senior-edmonton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0003],\n",
       "         [ 0.0123]]),\n",
       " tensor([0.]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.tensor(np.random.normal(0, 0.01, (num_inputs, 1)), dtype=torch.float32) \n",
    "b = torch.zeros(1, dtype=torch.float32)\n",
    "w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-research",
   "metadata": {},
   "source": [
    "在后面的模型训练中，需要对这些参数求梯度来迭代参数的值，因此要设置requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "auburn-active",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.requires_grad_(requires_grad=True)\n",
    "b.requires_grad_(requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-china",
   "metadata": {},
   "source": [
    "使用 𝐦𝐦() 函数做矩阵乘法，来实现线性回归的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "shaped-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linreg(X, w, b):\n",
    "    return torch.mm(X, w) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-subscriber",
   "metadata": {},
   "source": [
    "##### 损失函数和优化算法\n",
    "本实验使用`平方损失`来定义线性回归的损失函数。在实现中，我们需要把真实值 𝑦 变形成预测值 𝑦_h𝑎𝑡 形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "sporting-variable",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_loss(y_hat, y):\n",
    "    return (y_hat.view(y.size()) - y) ** 2 / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-israel",
   "metadata": {},
   "source": [
    "以下的 sgd 函数实现了小批量随机梯度下降算法。它通过不断迭代模型参数来优化损失函数。这里自动求梯度模块计算得来提速是一个批量样本的梯度和。我们将它除以批量大小来得到平均值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "moving-science",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params, lr, batch_size): \n",
    "    for param in params:\n",
    "        # 注意这里更改param时用的param.data\n",
    "        param.data -= lr * param.grad / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-premium",
   "metadata": {},
   "source": [
    "##### 模型训练\n",
    "在训练过程中，模型将会多次迭代更新参数。在每次迭代中，根据当前读取的小批量数据样本(特征 x 和标签 y)，通过调用反向函数backward 计算小批量随机梯度，并调用优化算法 𝐬𝐠𝐝 迭代模型参数 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "focused-gender",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.003513\n",
      "epoch 2, loss 0.000619\n",
      "epoch 3, loss 0.000144\n"
     ]
    }
   ],
   "source": [
    "lr = 0.03\n",
    "num_epochs = 3\n",
    "net = linreg\n",
    "loss = squared_loss\n",
    "batch_size = 32\n",
    "\n",
    "# 训练模型一共需要num_epochs个迭代周期\n",
    "for epoch in range(num_epochs): \n",
    "    \n",
    "    # 在每一个迭代周期中，会使用训练数据集中所有样本一次, x和y分别是小批量样本的特征和标签\n",
    "    for X, y in data_iter(batch_size, features, labels):\n",
    "        \n",
    "        # 这是一个二维向量\n",
    "        y_hat = net(X, w, b) \n",
    "        \n",
    "        # l是有关小批量X和y的损失\n",
    "        l = loss(y_hat, y).sum()  \n",
    "        \n",
    "        # 小批量的损失对模型参数求梯度\n",
    "        l.backward() \n",
    "        \n",
    "        # 使用小批量随机梯度下降迭代模型参数 \n",
    "        sgd([w, b], lr, batch_size) \n",
    "        \n",
    "        # 梯度清零\n",
    "        w.grad.data.zero_()\n",
    "        b.grad.data.zero_()\n",
    "        \n",
    "    train_l = loss(net(features, w, b), labels)\n",
    "    print('epoch %d, loss %f' % (epoch + 1, train_l.mean().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "mexican-broadway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2, -3.4],\n",
       " tensor([[ 1.9882],\n",
       "         [-3.3942]], requires_grad=True))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_w, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "checked-tracker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.2, tensor([4.1939], requires_grad=True))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_b, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-affiliate",
   "metadata": {},
   "source": [
    "#### 利用torch.nn实现线性回归\n",
    "Torch.nn 模块<br>\n",
    "+ Pytorch为神经网络设计的模块化接口，该模块定义了大量的神经网络层。<br>\n",
    "+ 𝐧𝐧 利用 `𝐚𝐮𝐭𝐨𝐠𝐫𝐚𝐝` 来定义模型，其核心数据结构是 `𝐌𝐨𝐝𝐮𝐥𝐞`。<br>\n",
    "\n",
    "下表给出了部分 𝐧𝐧 中所包含模块(其它模块可查阅官方API):\n",
    "\n",
    "|模块|作用|\n",
    "|:---:|:----:|\n",
    "|torch.nn.Module()|Module是所有神经网络模块的基类|\n",
    "|torch.nn.Linear()|Linear用于对输入数据进行线性变换|\n",
    "|torch.nn.Sequential()|Sequential是一个顺序容器, 其中模块的添加顺序与在构造函数中传递模块时的顺序相同|\n",
    "|torch.nn.MSELoss|MSELoss用于衡量输入 x 和目标 y 中每个元素之间的均方误差的标准。|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-purse",
   "metadata": {},
   "source": [
    "##### 读取数据\n",
    "PyTorch提供了 𝐝𝐚𝐭𝐚 库来读取数据。由于data常用作变量名，这里将导入的 𝐝𝐚𝐭𝐚 模块用 𝐃𝐚𝐭𝐚 代替。 对前面的读取数据部分可以使用 𝐝𝐚𝐭𝐚 库来处理。在每一次迭代中，使用 𝐃𝐚𝐭𝐚 随机读取包含10个数据 样本的小批量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ethical-arizona",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.03\n",
    "batch_size = 10\n",
    "\n",
    "# 将训练数据的特征和标签组合\n",
    "dataset = Data.TensorDataset(features, labels)\n",
    "\n",
    "# 把 dataset 放入 DataLoader\n",
    "data_iter = Data.DataLoader(\n",
    "    dataset=dataset,         # torch TensorDataset format\n",
    "    batch_size=batch_size,   # mini batch size\n",
    "    shuffle=True,            # 是否打乱数据 (训练集一般需要进行打乱) \n",
    "    num_workers=2,           # 多线程来读数据，注意在Windows下需要设置为0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-satisfaction",
   "metadata": {},
   "source": [
    "##### 构建模型\n",
    "构建模型的过程中，最常见的方法就是继承 𝐧𝐧. 𝐌𝐨𝐝𝐮𝐥𝐞, 然后构建自己的网络。<br>\n",
    "一个 𝐧𝐧.𝐌𝐨𝐝𝐮𝐥𝐞 实例需要包含一些层以及返回输出的前向传播方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "framed-apollo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearNet(\n",
       "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LinearNet(nn.Module):\n",
    "    def __init__(self, n_feature):\n",
    "        super(LinearNet, self).__init__() \n",
    "        self.linear = nn.Linear(n_feature, 1)\n",
    "        \n",
    "    # forward 定义前向传播\n",
    "    def forward(self, x): \n",
    "        y = self.linear(x) \n",
    "        return y\n",
    "    \n",
    "net = LinearNet(num_inputs)\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-comment",
   "metadata": {},
   "source": [
    "除了继承 𝐧𝐧.𝐌𝐨𝐮𝐝𝐥𝐞 来构建线性回归模型，还可以利用 𝐧𝐧.𝐒𝐞𝐪𝐮𝐞𝐧𝐭𝐢𝐚𝐥 结合 𝐧𝐧.𝐋𝐢𝐧𝐞𝐚𝐫 来搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "utility-admission",
   "metadata": {},
   "outputs": [],
   "source": [
    "#写法一\n",
    "net = nn.Sequential( \n",
    "    nn.Linear(num_inputs, 1) # 此处可以添加其它层\n",
    ")\n",
    "\n",
    "# 写法二\n",
    "# net = nn.Sequential()\n",
    "# net.add_module('linear', nn.Linear(num_inputs, 1)) \n",
    "# net.add_module.........\n",
    "\n",
    "# 写法三\n",
    "# from collections import OrderedDict\n",
    "# net = nn.Sequential(OrderedDict([\n",
    "# ('linear', nn.Linear(num_inputs, 1)) \n",
    "# ......]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-sunday",
   "metadata": {},
   "source": [
    "##### 模型参数初始化\n",
    "在使用定义的模型 net 之前，需要对模型中的一些参数进行初始化。PyTorch 在 init 模块 中提供了许多初始化参数的方法。我们可以调用𝐢𝐧𝐢𝐭.𝐧𝐨𝐫𝐦𝐚𝐥模块通过正态分布对线性回归中的权重和偏差进行初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "baking-rebel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.init.normal_(net[0].weight, mean=0, std=0.01)\n",
    "\n",
    "# 也可以直接修改bias的data:net[0].bias.data.fill_(0)\n",
    "nn.init.constant_(net[0].bias, val=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-assist",
   "metadata": {},
   "source": [
    "##### 损失函数和优化\n",
    "Pytorch 在 𝑡𝑜𝑟𝑐h.𝑛𝑛 中提供了各种损失函数，这些损失函数实现为 𝐧𝐧.𝐌𝐨𝐝𝐮𝐥𝐞 的子类，可以将这些损失函数作为一种特殊的层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "emerging-guidance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSELoss()"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.MSELoss()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-photograph",
   "metadata": {},
   "source": [
    "Pytorch在 𝐭𝐨𝐫𝐜𝐡.𝐨𝐩𝐭𝐢𝐦 模块中提供了诸如 𝑺𝑮𝑫、𝑨𝒅𝒂𝒎 和 𝑹𝑴𝑺𝑷𝒓𝒐𝒐𝒑 等优化算法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "colonial-effect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 梯度下降的学习率指定为0.03\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.03)\n",
    "\n",
    "# 可以为不同的子网络设置不同学习率\n",
    "# optimizer =optim.SGD([\n",
    "#     # 如果不指定学习率，则用默认的最外层学习率 \n",
    "#     {'params': net.subnet1.parameters()}，\n",
    "#     {'params': net.subnet2.parameters(), 'lr': 0.01}\n",
    "# ], lr=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-spank",
   "metadata": {},
   "source": [
    "##### 模型训练\n",
    "训练模型时，可以调用 𝐨𝐩𝐭𝐢𝐦 中的 𝐬𝐭𝐞𝐩() 函数来迭代模型参数。<br>\n",
    "按照小批量随机梯度下降的定义，在 𝐬𝐭𝐞𝐩() 函数中指定批量大小，从而对批量中的样本梯度求平均。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "thousand-empty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss: 0.000073\n",
      "epoch 2, loss: 0.000065\n",
      "epoch 3, loss: 0.000157\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    for X, y in data_iter: \n",
    "        output = net(X)\n",
    "        l = loss(output, y.view(-1, 1))\n",
    "\n",
    "        # 梯度清零，等价于net.zero_grad() \n",
    "        optimizer.zero_grad() \n",
    "\n",
    "        l.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    print('epoch %d, loss: %f' % (epoch, l.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-austin",
   "metadata": {},
   "source": [
    "##### 模型预测及评价\n",
    "对于分类问题，给定任一样本特征，模型可以预测每个输出类别的概率。通常，我们把预测概率最 大的类别作为输出类别。如果它与真实类别(标签)一致，说明这次预测是正确的。我们使用准确 率(accuracy)来评价模型的表现。它等于正确预测数量与总预测数量之比。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
